{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd48a22-2567-4638-9d23-c507eb6db083",
   "metadata": {},
   "source": [
    "### Advanced Python AI and ML Tools - Assignment 1\n",
    "\n",
    "__Group Members:__\n",
    "1) Aanal Patel - C0910376\n",
    "2) Bimal Shresta - C0919385\n",
    "3) Danilo Diaz - C0889539\n",
    "4) Ernie Sumoso - C0881591"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d8930-578d-4157-b1c5-368a73ef4b63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index\n",
    "- __Step 1. Dataset Description (web scrapped)__\n",
    "- __Step 2. Data Wrangling (cleaning, formatting, structuring, validating)__\n",
    "- __Step 3. Plotting methods for distribution__\n",
    "- __Step 4. Pandas profiling for EDA (exploratory data analysis)__\n",
    "- __Step 5. Encoding methods, creating new numerical columns__\n",
    "- __Step 6. Outlier identification (with boxplots and IQR)__\n",
    "- __Step 7. Addressing outliers with Quantile-based flooring and capping, Trimming, and Log Transformation__\n",
    "- __Step 8. Unsupervised learning methods__\n",
    "- __Step 9. NLP techniques (data cleaning, stopword and puctuation removal, tokenizing, stemming, and lemmatization)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3e558-267b-4d55-8b33-4c33c6e77d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1. Dataset Description (web scrapped)\n",
    "\n",
    "(Bimal add a description of what you did to web scrap the data here, what is the source and what were your steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45a9a780-fd82-442c-bce2-85cd9bc8e1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>job_location</th>\n",
       "      <th>post</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>company_qns</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The opportunityAs part of our exciting growth ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73930150?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>Labourforce</td>\n",
       "      <td>$47 per hour + penalties</td>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Our client is one of Australia's leading Manuf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73870879?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>Cendre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Cendré is a revered e-commerce jewellery brand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73875587?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Parramatta locationWork with a close-knit, exp...</td>\n",
       "      <td>Do you have demonstrated experience diagnosing...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73868216?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_title  \\\n",
       "2610                         Level 2/3 Support Engineer   \n",
       "2611  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "2612                            Casual Retail Assistant   \n",
       "2613                                   Studio Assistant   \n",
       "2614                          Junior IT Support Officer   \n",
       "\n",
       "                             company                       salary  \\\n",
       "2610         Fuse Technology Pty Ltd                          NaN   \n",
       "2611                     Labourforce     $47 per hour + penalties   \n",
       "2612  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "2613                          Cendre                          NaN   \n",
       "2614                   Hare & Forbes                          NaN   \n",
       "\n",
       "                    job_location  \\\n",
       "2610                  Sydney NSW   \n",
       "2611  Wetherill Park, Sydney NSW   \n",
       "2612        Randwick, Sydney NSW   \n",
       "2613    Oxenford, Gold Coast QLD   \n",
       "2614       Northmead, Sydney NSW   \n",
       "\n",
       "                                                   post         job_type  \\\n",
       "2610  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "2611  Warehousing, Storage & Distribution (Manufactu...    Contract/Temp   \n",
       "2612     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "2613  Pickers & Packers (Manufacturing, Transport & ...        Full time   \n",
       "2614  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "\n",
       "                                               job_desc  \\\n",
       "2610  The opportunityAs part of our exciting growth ...   \n",
       "2611  Our client is one of Australia's leading Manuf...   \n",
       "2612  Independent Living Specialists is a fast-growi...   \n",
       "2613  Cendré is a revered e-commerce jewellery brand...   \n",
       "2614  Parramatta locationWork with a close-knit, exp...   \n",
       "\n",
       "                                            company_qns job_posted_date  \\\n",
       "2610  Which of the following statements best describ...      2024-02-21   \n",
       "2611                                                NaN      2024-02-21   \n",
       "2612  Do you have customer service experience?Do you...      2024-02-21   \n",
       "2613                                                NaN      2024-02-21   \n",
       "2614  Do you have demonstrated experience diagnosing...      2024-02-21   \n",
       "\n",
       "                                               job_link  \n",
       "2610  https://www.seek.com.au/job/73930150?type=stan...  \n",
       "2611  https://www.seek.com.au/job/73870879?type=stan...  \n",
       "2612  https://www.seek.com.au/job/73899163?type=stan...  \n",
       "2613  https://www.seek.com.au/job/73875587?type=stan...  \n",
       "2614  https://www.seek.com.au/job/73868216?type=stan...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading the web scrapped data from CSV file, setting the index column\n",
    "df = pd.read_csv(\"job_data.csv\", index_col=0)\n",
    "\n",
    "# displaying the raw data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64d79c30-ba28-4b8b-a6ee-425ac8107091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 9800\n",
      "Number of Columns: 10\n",
      "Index(['job_title', 'company', 'salary', 'job_location', 'post', 'job_type',\n",
      "       'job_desc', 'company_qns', 'job_posted_date', 'job_link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# display the number of rows, columns and the column names\n",
    "def display_shape_and_colnames(df):\n",
    "    print(\"Number of Rows:\", df.shape[0])\n",
    "    print(\"Number of Columns:\", df.shape[1])\n",
    "    print(df.columns)\n",
    "    \n",
    "display_shape_and_colnames(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837f9d0-3dc3-4986-a9df-337ddc17e9b7",
   "metadata": {},
   "source": [
    "Some of our __column names__ are __redundant__ because we are working with job data.\n",
    "\n",
    "Let's delete the prefix __\"job\"__ from our column names.\n",
    "\n",
    "Some other __column names__ are __abbreviated__ (e.g. \"job_desc\", \"company_qns\").\n",
    "\n",
    "Let's __replace them with full names__ so we can have accurate column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb8e2f7a-9d56-4e39-8b51-b145d797646c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experienced Support Worker (PPT &amp; CAS)</td>\n",
       "      <td>Ability Gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>Wagga Wagga, Wagga Wagga &amp; Riverina NSW</td>\n",
       "      <td>Aged &amp; Disability Support (Community Services ...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regional Manager - Inspire@HOME</td>\n",
       "      <td>CatholicCare Tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Launceston, Launceston &amp; North East TAS</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title                company  \\\n",
       "0  Experienced Support Worker (PPT & CAS)        Ability Gateway   \n",
       "1         Regional Manager - Inspire@HOME  CatholicCare Tasmania   \n",
       "\n",
       "                  salary                                 location  \\\n",
       "0  $35.50 per hour [PPT]  Wagga Wagga, Wagga Wagga & Riverina NSW   \n",
       "1                    NaN  Launceston, Launceston & North East TAS   \n",
       "\n",
       "                                          department       type  \\\n",
       "0  Aged & Disability Support (Community Services ...  Part time   \n",
       "1  Child Welfare, Youth & Family Services (Commun...  Full time   \n",
       "\n",
       "                                         description  \\\n",
       "0  About usWe are an outcome focused NDIS service...   \n",
       "1  CatholicCare Tasmania is the primary social se...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  Do you own or have regular access to a car?Whi...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_colnames(df):\n",
    "    # delete the prefix \"job_\" on our column names\n",
    "    for column_name in df.columns.to_list():\n",
    "        if column_name.startswith(\"job_\"):\n",
    "            df.rename(columns={column_name : column_name.lstrip(\"job_\")}, inplace=True)\n",
    "\n",
    "    # rename abbreviated column names\n",
    "    df.rename(columns={'desc':'description', 'company_qns':'company_questions', 'post':'department'}, inplace=True)\n",
    "\n",
    "clean_colnames(df)\n",
    "# display clean column names\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7c020-0c61-4025-8b53-9283211d7ff5",
   "metadata": {},
   "source": [
    "Now let's undestand all of our columns by providing a description to each one:\n",
    "- __title__: title of the posted job\n",
    "- __company__: name of the company that has posted the job\n",
    "- __salary__: salary range for the job, can be defined per hour, monthly, annually, etc.\n",
    "- __location__: geographical location of the job or company\n",
    "- __department__: field or department of the job (e.g. IT, Sales, etc.)\n",
    "- __description__: long description of the job posting\n",
    "- __company_questions__: questions issued by the company to the applicants, according to the post\n",
    "- __posted_date__: format yyyy-mm-dd\n",
    "- __link__: link of the job posting\n",
    "\n",
    "Now that we have a general understanding of our web scrapped data. \n",
    "\n",
    "Let's go ahead to the next step to perform our data wrangling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7c8b0-5e4d-44bc-9c1f-253acadabe00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2. Data Wrangling (cleaning, formatting, structuring, validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22d8490f-0b52-4dea-ac76-d5fd4e4b5dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Missing Values\n",
      "title                   0\n",
      "company                 0\n",
      "salary               5216\n",
      "location                0\n",
      "department              0\n",
      "type                    0\n",
      "description             0\n",
      "company_questions    5034\n",
      "posted_date             0\n",
      "link                    0\n",
      "dtype: int64\n",
      "\n",
      "% Missing Values\n",
      "title                 0.000000\n",
      "company               0.000000\n",
      "salary               53.224490\n",
      "location              0.000000\n",
      "department            0.000000\n",
      "type                  0.000000\n",
      "description           0.000000\n",
      "company_questions    51.367347\n",
      "posted_date           0.000000\n",
      "link                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    # check for number of missing values per column\n",
    "    print(\"# Missing Values\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # check for % of missing values\n",
    "    print(\"\\n% Missing Values\")\n",
    "    print(df.isna().mean() * 100)\n",
    "    \n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511b597-6839-49ed-9fcb-852fce895035",
   "metadata": {},
   "source": [
    "As expected, many job posts do not include a salary range or any information about the salary.\n",
    "\n",
    "It is no surprise that __more than half of our data has missing values for salary__.\n",
    "\n",
    "On the other hand, we also have __more than half missing values for the company questions column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c435ba31-552a-4e09-898d-80df73894ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Duplicated Values\n",
      "944\n",
      "\n",
      "% Duplicated Values\n",
      "9.63265306122449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>Pick Packers</td>\n",
       "      <td>Action Workforce</td>\n",
       "      <td>35</td>\n",
       "      <td>Maddington, Perth WA</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Action Workforce are looking for Experienced P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901168?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>Accounts Person- KALGOORLIE RESIDENTS ONLY</td>\n",
       "      <td>Golden mile cleaning services</td>\n",
       "      <td>$30 – $33.50 per hour</td>\n",
       "      <td>Kalgoorlie, Kalgoorlie, Goldfields &amp; Esperance WA</td>\n",
       "      <td>Administrative Assistants (Administration &amp; Of...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>Job Title: Accounts Person We are currently se...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73908087?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>Warehouse Assistant</td>\n",
       "      <td>Omni Recruit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truganina, Melbourne VIC</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Business is booming and we are currently seeki...</td>\n",
       "      <td>Do you agree to the privacy policy of Omni Rec...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73863322?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "2587                                Pick Packers   \n",
       "2593  Accounts Person- KALGOORLIE RESIDENTS ONLY   \n",
       "2603                         Warehouse Assistant   \n",
       "2612                     Casual Retail Assistant   \n",
       "\n",
       "                             company                       salary  \\\n",
       "2587                Action Workforce                           35   \n",
       "2593   Golden mile cleaning services        $30 – $33.50 per hour   \n",
       "2603                    Omni Recruit                          NaN   \n",
       "2612  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "\n",
       "                                               location  \\\n",
       "2587                               Maddington, Perth WA   \n",
       "2593  Kalgoorlie, Kalgoorlie, Goldfields & Esperance WA   \n",
       "2603                           Truganina, Melbourne VIC   \n",
       "2612                               Randwick, Sydney NSW   \n",
       "\n",
       "                                             department             type  \\\n",
       "2587  Warehousing, Storage & Distribution (Manufactu...  Casual/Vacation   \n",
       "2593  Administrative Assistants (Administration & Of...        Part time   \n",
       "2603  Pickers & Packers (Manufacturing, Transport & ...  Casual/Vacation   \n",
       "2612     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "\n",
       "                                            description  \\\n",
       "2587  Action Workforce are looking for Experienced P...   \n",
       "2593  Job Title: Accounts Person We are currently se...   \n",
       "2603  Business is booming and we are currently seeki...   \n",
       "2612  Independent Living Specialists is a fast-growi...   \n",
       "\n",
       "                                      company_questions posted_date  \\\n",
       "2587                                                NaN  2024-02-21   \n",
       "2593  Which of the following statements best describ...  2024-02-21   \n",
       "2603  Do you agree to the privacy policy of Omni Rec...  2024-02-20   \n",
       "2612  Do you have customer service experience?Do you...  2024-02-21   \n",
       "\n",
       "                                                   link  \n",
       "2587  https://www.seek.com.au/job/73901168?type=stan...  \n",
       "2593  https://www.seek.com.au/job/73908087?type=prom...  \n",
       "2603  https://www.seek.com.au/job/73863322?type=stan...  \n",
       "2612  https://www.seek.com.au/job/73899163?type=stan...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_duplicated_values(df):\n",
    "    # check for number of duplicated values\n",
    "    print(\"# Duplicated Values\")\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    # check for % of duplicated values\n",
    "    print(\"\\n% Duplicated Values\")\n",
    "    print(df.duplicated().mean() * 100)\n",
    "\n",
    "check_duplicated_values(df)\n",
    "\n",
    "df[df.duplicated()].tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141d4cf-c61e-4847-bc3f-49c84247f2d6",
   "metadata": {},
   "source": [
    "Some considerable amount of our data __(around 9.5%) are duplicated__ rows.\n",
    "\n",
    "This can be __dangerous for analysis__, as it can affect multiple metrics and our model training.\n",
    "\n",
    "We have to __deal with these duplicated values__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0f48a36-28e8-4ff6-8df1-57c0f9c822f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Values per Column\n",
      "'title' # of unique values: 5655\n",
      "'company' # of unique values: 4965\n",
      "'salary' # of unique values: 2645\n",
      "'location' # of unique values: 1448\n",
      "'department' # of unique values: 451\n",
      "'type' # of unique values: 8\n",
      "'description' # of unique values: 7958\n",
      "'company_questions' # of unique values: 2730\n",
      "'posted_date' # of unique values: 95\n",
      "'link' # of unique values: 8664\n",
      "\n",
      "% Unique Values per Column\n",
      "'title' % of unique values: 57.7 %\n",
      "'company' % of unique values: 50.66 %\n",
      "'salary' % of unique values: 26.99 %\n",
      "'location' % of unique values: 14.78 %\n",
      "'department' % of unique values: 4.6 %\n",
      "'type' % of unique values: 0.08 %\n",
      "'description' % of unique values: 81.2 %\n",
      "'company_questions' % of unique values: 27.86 %\n",
      "'posted_date' % of unique values: 0.97 %\n",
      "'link' % of unique values: 88.41 %\n"
     ]
    }
   ],
   "source": [
    "def check_nunique_values(df):\n",
    "    # check number of unique values per column\n",
    "    print(\"# Unique Values per Column\")\n",
    "    for col in df.columns:\n",
    "        print(\"'\"+col+\"'\", \"# of unique values:\", df[col].nunique())\n",
    "        \n",
    "    # check % of unique values per column (relative to number of total rows in the dataset)\n",
    "    print(\"\\n% Unique Values per Column\")\n",
    "    for col in df.columns:\n",
    "        print(\"'\"+col+\"'\", \"% of unique values:\", round(df[col].nunique() * 100 / df.shape[0], 2), \"%\")\n",
    "        \n",
    "check_nunique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e88d6-fc2a-4f32-aa18-43a753474b66",
   "metadata": {},
   "source": [
    "Some of our columns have a __large amount of unique values__.\n",
    "\n",
    "Although we still have not processed our values, we must __seek to reduce the number of unique values through data processing__.\n",
    "\n",
    "These are some of the columns with vast amount of unique values __(>50% of total rows)__:\n",
    "- title\n",
    "- company\n",
    "- description\n",
    "- link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b21c6f5e-c349-4791-84e4-c6e71fd87e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopwords(tokens, add_stopwords=[]):\n",
    "    i = 0\n",
    "    total_stopwords = stopwords.words('english') + add_stopwords\n",
    "    while i < len(tokens):\n",
    "        if tokens[i] in total_stopwords:\n",
    "            tokens.pop(i)\n",
    "            i -= 1\n",
    "        i += 1\n",
    "\n",
    "def remove_digits(tokens):\n",
    "    for i, word in enumerate(tokens):\n",
    "        tokens[i] = re.sub(r'\\d+', '', word)\n",
    "    return [word for word in tokens if word != \"\"]\n",
    "\n",
    "def remove_short_words(tokens, min_length, exceptions=[]):\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if len(tokens[i]) < min_length and tokens[i] not in exceptions:\n",
    "            tokens.pop(i)\n",
    "            i -= 1\n",
    "        i += 1\n",
    "        \n",
    "def populate_len_words(tokens):\n",
    "    counts = [], [], []\n",
    "    for word in tokens:\n",
    "        if len(word) > 0 and len(word) <= len(counts):\n",
    "            counts[len(word) - 1].append(word)\n",
    "    return counts\n",
    "        \n",
    "len_1 = []\n",
    "len_2 = []\n",
    "len_3 = []\n",
    "words_count = {}\n",
    "bigram_count = {}\n",
    "trigram_count = {}\n",
    "for title_value in df['title'].unique():\n",
    "    # remove punctuation from the title value\n",
    "    title_no_punc = title_value.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # word tokenize the title value\n",
    "    word_tokens = word_tokenize(title_no_punc)\n",
    "    \n",
    "    # lower word tokens\n",
    "    word_tokens = list(map(str.lower, word_tokens))\n",
    "    \n",
    "    # remove stopwords\n",
    "    add_stopwords = ['ict', 'plus', 'per', 'week', 'bws', 'new', 'asap', 'pae', 'year', 'years', 'itc', 'day']\n",
    "    remove_stopwords(word_tokens, add_stopwords)\n",
    "    \n",
    "    # remove shorter words (abbreviations)\n",
    "    exceptions = ['hr']\n",
    "    min_length = 3\n",
    "    remove_short_words(word_tokens, min_length, exceptions)\n",
    "    \n",
    "    # remove digits\n",
    "    word_tokens = remove_digits(word_tokens)\n",
    "    \n",
    "    # populate 1, 2, and 3 len words\n",
    "    current_words = populate_len_words(word_tokens)\n",
    "    len_1 += current_words[0]\n",
    "    len_2 += current_words[1]\n",
    "    len_3 += current_words[2]\n",
    "    \n",
    "    # build bigrams from word tokens\n",
    "    bigrams = []\n",
    "    for i in range(len(word_tokens)-1):\n",
    "        bigrams.append(word_tokens[i] + ' ' + word_tokens[i+1])\n",
    "    \n",
    "    # build bigrams from word tokens\n",
    "    trigrams = []\n",
    "    for i in range(len(word_tokens)-2):\n",
    "        trigrams.append(word_tokens[i] + ' ' + word_tokens[i+1] + ' ' + word_tokens[i+2])\n",
    "    \n",
    "    # update the word counter\n",
    "    for word in word_tokens:\n",
    "        words_count[word] = words_count.get(word, 0) + 1\n",
    "    \n",
    "    # update the bigrams\n",
    "    for bigram in bigrams:\n",
    "        bigram_count[bigram] = bigram_count.get(bigram, 0) + 1\n",
    "    \n",
    "    # update the trigrams\n",
    "    for trigram in trigrams:\n",
    "        trigram_count[trigram] = trigram_count.get(bigram, 0) + 1\n",
    "    \n",
    "words_sorted = sorted(words_count.items(), key=lambda x : x[1], reverse=True)\n",
    "bigrams_sorted = sorted(bigram_count.items(), key=lambda x : x[1], reverse=True)\n",
    "trigrams_sorted = sorted(trigram_count.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "319f191a-4420-4279-afac-e9dbe5dfe12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'a', 'y', 'f', 'k']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(len_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "236b2464-0bc5-4450-abc2-6f094b84bcb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'hr', 'el', 'hm', 'px', 'nd', 'po', 'pm', 'bb', 'oo', 'ao', 'am', 'ic']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(len_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ac78c7f3-d9fa-48fe-a61b-ab3edf0764c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bas',\n",
       " 'sap',\n",
       " 'ald',\n",
       " 'mid',\n",
       " 'elm',\n",
       " 'aod',\n",
       " 'sub',\n",
       " 'try',\n",
       " 'ivf',\n",
       " 'qsr',\n",
       " 'fix',\n",
       " 'smp',\n",
       " 'eca',\n",
       " 'gis',\n",
       " 'esg',\n",
       " 'gin',\n",
       " 'car',\n",
       " 'aws',\n",
       " 'euc',\n",
       " 'rpd',\n",
       " 'sme',\n",
       " 'whv',\n",
       " 'uni',\n",
       " 'net',\n",
       " 'qld',\n",
       " 'alh',\n",
       " 'due',\n",
       " 'hbc',\n",
       " 'jmf',\n",
       " 'cns',\n",
       " 'bdm',\n",
       " 'fit',\n",
       " 'bid',\n",
       " 'far',\n",
       " 'cbd',\n",
       " 'ute',\n",
       " 'inc',\n",
       " 'pmo',\n",
       " 'fpa',\n",
       " 'sil',\n",
       " 'anz',\n",
       " 'pty',\n",
       " 'ims',\n",
       " 'sor',\n",
       " 'two',\n",
       " 'acm',\n",
       " 'fom',\n",
       " 'hcp',\n",
       " 'trc',\n",
       " 'eho',\n",
       " 'ote',\n",
       " 'cnc',\n",
       " 'imc',\n",
       " 'rab',\n",
       " 'kit',\n",
       " 'aso',\n",
       " 'cps',\n",
       " 'ras',\n",
       " 'gpc',\n",
       " 'law',\n",
       " 'jay',\n",
       " 'woy',\n",
       " 'png',\n",
       " 'pqe',\n",
       " 'cas',\n",
       " 'job',\n",
       " 'whs',\n",
       " 'hsp',\n",
       " 'ecm',\n",
       " 'gmp',\n",
       " 'mep',\n",
       " 'wet',\n",
       " 'vps',\n",
       " 'itt',\n",
       " 'iga',\n",
       " 'pcp',\n",
       " 'ses',\n",
       " 'ctp',\n",
       " 'non',\n",
       " 'ceo',\n",
       " 'arc',\n",
       " 'rda',\n",
       " 'vic',\n",
       " 'msp',\n",
       " 'aps',\n",
       " 'exp',\n",
       " 'one',\n",
       " 'pet',\n",
       " 'stp',\n",
       " 'ngs',\n",
       " 'bay',\n",
       " 'ame',\n",
       " 'van',\n",
       " 'wfh',\n",
       " 'wfa',\n",
       " 'pos',\n",
       " 'yha',\n",
       " 'tas',\n",
       " 'crk',\n",
       " 'bft',\n",
       " 'cmt',\n",
       " 'cad',\n",
       " 'dna',\n",
       " 'bar',\n",
       " 'eso',\n",
       " 'ops',\n",
       " 'ltd',\n",
       " 'lvl',\n",
       " 'syd',\n",
       " 'sea',\n",
       " 'tax',\n",
       " 'egm',\n",
       " 'rep',\n",
       " 'end',\n",
       " 'apy',\n",
       " 'ttw',\n",
       " 'rto',\n",
       " 'nfp',\n",
       " 'spa',\n",
       " 'icp',\n",
       " 'app',\n",
       " 'web',\n",
       " 'mcv',\n",
       " 'pts',\n",
       " 'phd',\n",
       " 'bms',\n",
       " 'get',\n",
       " 'bom',\n",
       " 'gym',\n",
       " 'seo',\n",
       " 'mgr',\n",
       " 'mth',\n",
       " 'top',\n",
       " 'gcf',\n",
       " 'key',\n",
       " 'dev',\n",
       " 'ray',\n",
       " 'pay',\n",
       " 'cpc',\n",
       " 'cmy',\n",
       " 'dry',\n",
       " 'nth',\n",
       " 'abn',\n",
       " 'ion',\n",
       " 'asx',\n",
       " 'act',\n",
       " 'coo',\n",
       " 'ehs',\n",
       " 'dog',\n",
       " 'org',\n",
       " 'gap',\n",
       " 'nnw',\n",
       " 'ccs',\n",
       " 'emu',\n",
       " 'otc',\n",
       " 'lab',\n",
       " 'cdc',\n",
       " 'fun',\n",
       " 'llc',\n",
       " 'psu',\n",
       " 'aid',\n",
       " 'nsw',\n",
       " 'wmc',\n",
       " 'bus',\n",
       " 'atm',\n",
       " 'fte',\n",
       " 'nmr',\n",
       " 'foi',\n",
       " 'ags',\n",
       " 'dfo',\n",
       " 'dfv',\n",
       " 'elc',\n",
       " 'ppt',\n",
       " 'csl',\n",
       " 'bgs',\n",
       " 'div',\n",
       " 'crm',\n",
       " 'cfo',\n",
       " 'age',\n",
       " 'vce',\n",
       " 'set',\n",
       " 'ali',\n",
       " 'tmp',\n",
       " 'occ',\n",
       " 'ftc',\n",
       " 'tcs',\n",
       " 'eoi',\n",
       " 'iso',\n",
       " 'moe',\n",
       " 'veg',\n",
       " 'tea',\n",
       " 'fld',\n",
       " 'lms',\n",
       " 'air',\n",
       " 'box',\n",
       " 'daf',\n",
       " 'pre',\n",
       " 'spt',\n",
       " 'hub',\n",
       " 'esd',\n",
       " 'gas',\n",
       " 'aus',\n",
       " 'isa',\n",
       " 'num']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(len_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
