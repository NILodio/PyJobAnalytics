{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd48a22-2567-4638-9d23-c507eb6db083",
   "metadata": {},
   "source": [
    "### Advanced Python AI and ML Tools - Assignment 1\n",
    "\n",
    "__Group Members:__\n",
    "1) Aanal Patel - C0910376\n",
    "2) Bimal Shresta - C0919385\n",
    "3) Danilo Diaz - C0889539\n",
    "4) Ernie Sumoso - C0881591"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d8930-578d-4157-b1c5-368a73ef4b63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index\n",
    "- __Step 1. Dataset Description (web scrapped)__\n",
    "- __Step 2. Data Wrangling (cleaning, formatting, structuring, validating)__\n",
    "    - __Step 9. NLP techniques: data cleaning, stopword and puctuation removal, tokenizing, ngrams analysis__\n",
    "- __Step 3. Plotting methods for distribution__\n",
    "- __Step 4. Pandas profiling for EDA (exploratory data analysis)__\n",
    "- __Step 5. Encoding methods, creating new numerical columns__\n",
    "- __Step 6. Outlier identification (with boxplots and IQR)__\n",
    "- __Step 7. Addressing outliers with Quantile-based flooring and capping, Trimming, and Log Transformation__\n",
    "- __Step 8. Unsupervised learning methods__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3e558-267b-4d55-8b33-4c33c6e77d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1. Dataset Description (web scrapped)\n",
    "\n",
    "(Bimal add a description of what you did to web scrap the data here, what is the source and what were your steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a9a780-fd82-442c-bce2-85cd9bc8e1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>job_location</th>\n",
       "      <th>post</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>company_qns</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The opportunityAs part of our exciting growth ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73930150?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>Labourforce</td>\n",
       "      <td>$47 per hour + penalties</td>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Our client is one of Australia's leading Manuf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73870879?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>Cendre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Cendré is a revered e-commerce jewellery brand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73875587?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Parramatta locationWork with a close-knit, exp...</td>\n",
       "      <td>Do you have demonstrated experience diagnosing...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73868216?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_title  \\\n",
       "2610                         Level 2/3 Support Engineer   \n",
       "2611  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "2612                            Casual Retail Assistant   \n",
       "2613                                   Studio Assistant   \n",
       "2614                          Junior IT Support Officer   \n",
       "\n",
       "                             company                       salary  \\\n",
       "2610         Fuse Technology Pty Ltd                          NaN   \n",
       "2611                     Labourforce     $47 per hour + penalties   \n",
       "2612  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "2613                          Cendre                          NaN   \n",
       "2614                   Hare & Forbes                          NaN   \n",
       "\n",
       "                    job_location  \\\n",
       "2610                  Sydney NSW   \n",
       "2611  Wetherill Park, Sydney NSW   \n",
       "2612        Randwick, Sydney NSW   \n",
       "2613    Oxenford, Gold Coast QLD   \n",
       "2614       Northmead, Sydney NSW   \n",
       "\n",
       "                                                   post         job_type  \\\n",
       "2610  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "2611  Warehousing, Storage & Distribution (Manufactu...    Contract/Temp   \n",
       "2612     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "2613  Pickers & Packers (Manufacturing, Transport & ...        Full time   \n",
       "2614  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "\n",
       "                                               job_desc  \\\n",
       "2610  The opportunityAs part of our exciting growth ...   \n",
       "2611  Our client is one of Australia's leading Manuf...   \n",
       "2612  Independent Living Specialists is a fast-growi...   \n",
       "2613  Cendré is a revered e-commerce jewellery brand...   \n",
       "2614  Parramatta locationWork with a close-knit, exp...   \n",
       "\n",
       "                                            company_qns job_posted_date  \\\n",
       "2610  Which of the following statements best describ...      2024-02-21   \n",
       "2611                                                NaN      2024-02-21   \n",
       "2612  Do you have customer service experience?Do you...      2024-02-21   \n",
       "2613                                                NaN      2024-02-21   \n",
       "2614  Do you have demonstrated experience diagnosing...      2024-02-21   \n",
       "\n",
       "                                               job_link  \n",
       "2610  https://www.seek.com.au/job/73930150?type=stan...  \n",
       "2611  https://www.seek.com.au/job/73870879?type=stan...  \n",
       "2612  https://www.seek.com.au/job/73899163?type=stan...  \n",
       "2613  https://www.seek.com.au/job/73875587?type=stan...  \n",
       "2614  https://www.seek.com.au/job/73868216?type=stan...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading the web scrapped data from CSV file, setting the index column\n",
    "df = pd.read_csv(\"job_data.csv\", index_col=0)\n",
    "\n",
    "# displaying the raw data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d79c30-ba28-4b8b-a6ee-425ac8107091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 9800\n",
      "Number of Columns: 10\n",
      "Index(['job_title', 'company', 'salary', 'job_location', 'post', 'job_type',\n",
      "       'job_desc', 'company_qns', 'job_posted_date', 'job_link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# display the number of rows, columns and the column names\n",
    "def display_shape_and_colnames(df):\n",
    "    print(\"Number of Rows:\", df.shape[0])\n",
    "    print(\"Number of Columns:\", df.shape[1])\n",
    "    print(df.columns)\n",
    "    \n",
    "display_shape_and_colnames(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837f9d0-3dc3-4986-a9df-337ddc17e9b7",
   "metadata": {},
   "source": [
    "Some of our __column names__ are __redundant__ because we are working with job data.\n",
    "\n",
    "Let's delete the prefix __\"job\"__ from our column names.\n",
    "\n",
    "Some other __column names__ are __abbreviated__ (e.g. \"job_desc\", \"company_qns\").\n",
    "\n",
    "Let's __replace them with full names__ so we can have accurate column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8e2f7a-9d56-4e39-8b51-b145d797646c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experienced Support Worker (PPT &amp; CAS)</td>\n",
       "      <td>Ability Gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>Wagga Wagga, Wagga Wagga &amp; Riverina NSW</td>\n",
       "      <td>Aged &amp; Disability Support (Community Services ...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regional Manager - Inspire@HOME</td>\n",
       "      <td>CatholicCare Tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Launceston, Launceston &amp; North East TAS</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title                company  \\\n",
       "0  Experienced Support Worker (PPT & CAS)        Ability Gateway   \n",
       "1         Regional Manager - Inspire@HOME  CatholicCare Tasmania   \n",
       "\n",
       "                  salary                                 location  \\\n",
       "0  $35.50 per hour [PPT]  Wagga Wagga, Wagga Wagga & Riverina NSW   \n",
       "1                    NaN  Launceston, Launceston & North East TAS   \n",
       "\n",
       "                                          department       type  \\\n",
       "0  Aged & Disability Support (Community Services ...  Part time   \n",
       "1  Child Welfare, Youth & Family Services (Commun...  Full time   \n",
       "\n",
       "                                         description  \\\n",
       "0  About usWe are an outcome focused NDIS service...   \n",
       "1  CatholicCare Tasmania is the primary social se...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  Do you own or have regular access to a car?Whi...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_colnames(df):\n",
    "    # delete the prefix \"job_\" on our column names\n",
    "    for column_name in df.columns.to_list():\n",
    "        if column_name.startswith(\"job_\"):\n",
    "            df.rename(columns={column_name : column_name.lstrip(\"job_\")}, inplace=True)\n",
    "\n",
    "    # rename abbreviated column names\n",
    "    df.rename(columns={'desc':'description', 'company_qns':'company_questions', 'post':'department'}, inplace=True)\n",
    "\n",
    "clean_colnames(df)\n",
    "# display clean column names\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7c020-0c61-4025-8b53-9283211d7ff5",
   "metadata": {},
   "source": [
    "Now let's undestand all of our columns by providing a description to each one:\n",
    "- __title__: title of the posted job\n",
    "- __company__: name of the company that has posted the job\n",
    "- __salary__: salary range for the job, can be defined per hour, monthly, annually, etc.\n",
    "- __location__: geographical location of the job or company\n",
    "- __department__: field or department of the job (e.g. IT, Sales, etc.)\n",
    "- __description__: long description of the job posting\n",
    "- __company_questions__: questions issued by the company to the applicants, according to the post\n",
    "- __posted_date__: format yyyy-mm-dd\n",
    "- __link__: link of the job posting\n",
    "\n",
    "Now that we have a general understanding of our web scrapped data. \n",
    "\n",
    "Let's go ahead to the next step to perform our data wrangling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7c8b0-5e4d-44bc-9c1f-253acadabe00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Step 2.__ Data Wrangling (cleaning, formatting, structuring, validating)\n",
    "### (includes __Step 9.__ NLP techniques: data cleaning, stopword and puctuation removal, tokenizing, ngrams analysis)\n",
    "\n",
    "First of all, we have 9800 rows, however the index values are repetead thrice because of the CSV contents.\n",
    "\n",
    "Let's start by reseting the index to have proper index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ba62e5-9313-4bb3-aa44-92bc5f8ca10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The opportunityAs part of our exciting growth ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73930150?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>Labourforce</td>\n",
       "      <td>$47 per hour + penalties</td>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Our client is one of Australia's leading Manuf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73870879?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>Cendre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Cendré is a revered e-commerce jewellery brand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73875587?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Parramatta locationWork with a close-knit, exp...</td>\n",
       "      <td>Do you have demonstrated experience diagnosing...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73868216?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "9795                         Level 2/3 Support Engineer   \n",
       "9796  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "9797                            Casual Retail Assistant   \n",
       "9798                                   Studio Assistant   \n",
       "9799                          Junior IT Support Officer   \n",
       "\n",
       "                             company                       salary  \\\n",
       "9795         Fuse Technology Pty Ltd                          NaN   \n",
       "9796                     Labourforce     $47 per hour + penalties   \n",
       "9797  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "9798                          Cendre                          NaN   \n",
       "9799                   Hare & Forbes                          NaN   \n",
       "\n",
       "                        location  \\\n",
       "9795                  Sydney NSW   \n",
       "9796  Wetherill Park, Sydney NSW   \n",
       "9797        Randwick, Sydney NSW   \n",
       "9798    Oxenford, Gold Coast QLD   \n",
       "9799       Northmead, Sydney NSW   \n",
       "\n",
       "                                             department             type  \\\n",
       "9795  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "9796  Warehousing, Storage & Distribution (Manufactu...    Contract/Temp   \n",
       "9797     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "9798  Pickers & Packers (Manufacturing, Transport & ...        Full time   \n",
       "9799  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "\n",
       "                                            description  \\\n",
       "9795  The opportunityAs part of our exciting growth ...   \n",
       "9796  Our client is one of Australia's leading Manuf...   \n",
       "9797  Independent Living Specialists is a fast-growi...   \n",
       "9798  Cendré is a revered e-commerce jewellery brand...   \n",
       "9799  Parramatta locationWork with a close-knit, exp...   \n",
       "\n",
       "                                      company_questions posted_date  \\\n",
       "9795  Which of the following statements best describ...  2024-02-21   \n",
       "9796                                                NaN  2024-02-21   \n",
       "9797  Do you have customer service experience?Do you...  2024-02-21   \n",
       "9798                                                NaN  2024-02-21   \n",
       "9799  Do you have demonstrated experience diagnosing...  2024-02-21   \n",
       "\n",
       "                                                   link  \n",
       "9795  https://www.seek.com.au/job/73930150?type=stan...  \n",
       "9796  https://www.seek.com.au/job/73870879?type=stan...  \n",
       "9797  https://www.seek.com.au/job/73899163?type=stan...  \n",
       "9798  https://www.seek.com.au/job/73875587?type=stan...  \n",
       "9799  https://www.seek.com.au/job/73868216?type=stan...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the rows index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276f656-3fad-4023-a673-e95481b2d89c",
   "metadata": {},
   "source": [
    "Now, let's perform some basic analysis on our dataset.\n",
    "\n",
    "We will check the following stats by implementing functions:\n",
    "- missing values per column\n",
    "- duplicated rows\n",
    "- number of unique values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d8490f-0b52-4dea-ac76-d5fd4e4b5dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Missing Values\n",
      "title                   0\n",
      "company                 0\n",
      "salary               5216\n",
      "location                0\n",
      "department              0\n",
      "type                    0\n",
      "description             0\n",
      "company_questions    5034\n",
      "posted_date             0\n",
      "link                    0\n",
      "dtype: int64\n",
      "\n",
      "% Missing Values\n",
      "title                 0.000000\n",
      "company               0.000000\n",
      "salary               53.224490\n",
      "location              0.000000\n",
      "department            0.000000\n",
      "type                  0.000000\n",
      "description           0.000000\n",
      "company_questions    51.367347\n",
      "posted_date           0.000000\n",
      "link                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    # check for number of missing values per column\n",
    "    print(\"# Missing Values\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # check for % of missing values\n",
    "    print(\"\\n% Missing Values\")\n",
    "    print(df.isna().mean() * 100)\n",
    "    \n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511b597-6839-49ed-9fcb-852fce895035",
   "metadata": {},
   "source": [
    "As expected, many job posts do not include a salary range or any information about the salary.\n",
    "\n",
    "It is no surprise that __more than half of our data has missing values for salary__.\n",
    "\n",
    "We also have __more than half missing values for the company questions column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c435ba31-552a-4e09-898d-80df73894ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Duplicated Values\n",
      "944\n",
      "\n",
      "% Duplicated Values\n",
      "9.63265306122449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>Pick Packers</td>\n",
       "      <td>Action Workforce</td>\n",
       "      <td>35</td>\n",
       "      <td>Maddington, Perth WA</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Action Workforce are looking for Experienced P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901168?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>Accounts Person- KALGOORLIE RESIDENTS ONLY</td>\n",
       "      <td>Golden mile cleaning services</td>\n",
       "      <td>$30 – $33.50 per hour</td>\n",
       "      <td>Kalgoorlie, Kalgoorlie, Goldfields &amp; Esperance WA</td>\n",
       "      <td>Administrative Assistants (Administration &amp; Of...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>Job Title: Accounts Person We are currently se...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73908087?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9788</th>\n",
       "      <td>Warehouse Assistant</td>\n",
       "      <td>Omni Recruit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truganina, Melbourne VIC</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Business is booming and we are currently seeki...</td>\n",
       "      <td>Do you agree to the privacy policy of Omni Rec...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73863322?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "9772                                Pick Packers   \n",
       "9778  Accounts Person- KALGOORLIE RESIDENTS ONLY   \n",
       "9788                         Warehouse Assistant   \n",
       "9797                     Casual Retail Assistant   \n",
       "\n",
       "                             company                       salary  \\\n",
       "9772                Action Workforce                           35   \n",
       "9778   Golden mile cleaning services        $30 – $33.50 per hour   \n",
       "9788                    Omni Recruit                          NaN   \n",
       "9797  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "\n",
       "                                               location  \\\n",
       "9772                               Maddington, Perth WA   \n",
       "9778  Kalgoorlie, Kalgoorlie, Goldfields & Esperance WA   \n",
       "9788                           Truganina, Melbourne VIC   \n",
       "9797                               Randwick, Sydney NSW   \n",
       "\n",
       "                                             department             type  \\\n",
       "9772  Warehousing, Storage & Distribution (Manufactu...  Casual/Vacation   \n",
       "9778  Administrative Assistants (Administration & Of...        Part time   \n",
       "9788  Pickers & Packers (Manufacturing, Transport & ...  Casual/Vacation   \n",
       "9797     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "\n",
       "                                            description  \\\n",
       "9772  Action Workforce are looking for Experienced P...   \n",
       "9778  Job Title: Accounts Person We are currently se...   \n",
       "9788  Business is booming and we are currently seeki...   \n",
       "9797  Independent Living Specialists is a fast-growi...   \n",
       "\n",
       "                                      company_questions posted_date  \\\n",
       "9772                                                NaN  2024-02-21   \n",
       "9778  Which of the following statements best describ...  2024-02-21   \n",
       "9788  Do you agree to the privacy policy of Omni Rec...  2024-02-20   \n",
       "9797  Do you have customer service experience?Do you...  2024-02-21   \n",
       "\n",
       "                                                   link  \n",
       "9772  https://www.seek.com.au/job/73901168?type=stan...  \n",
       "9778  https://www.seek.com.au/job/73908087?type=prom...  \n",
       "9788  https://www.seek.com.au/job/73863322?type=stan...  \n",
       "9797  https://www.seek.com.au/job/73899163?type=stan...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_duplicated_values(df):\n",
    "    # check for number of duplicated values\n",
    "    print(\"# Duplicated Values\")\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    # check for % of duplicated values\n",
    "    print(\"\\n% Duplicated Values\")\n",
    "    print(df.duplicated().mean() * 100)\n",
    "\n",
    "check_duplicated_values(df)\n",
    "\n",
    "df[df.duplicated()].tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141d4cf-c61e-4847-bc3f-49c84247f2d6",
   "metadata": {},
   "source": [
    "Some considerable amount of our data __(around 9.5%) are duplicated__ rows.\n",
    "\n",
    "This can be __dangerous for analysis__, we have to __deal with these duplicated values__ in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f48a36-28e8-4ff6-8df1-57c0f9c822f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Values per Column\n",
      "'title' # of unique values: 5655\n",
      "'company' # of unique values: 4965\n",
      "'salary' # of unique values: 2645\n",
      "'location' # of unique values: 1448\n",
      "'department' # of unique values: 451\n",
      "'type' # of unique values: 8\n",
      "'description' # of unique values: 7958\n",
      "'company_questions' # of unique values: 2730\n",
      "'posted_date' # of unique values: 95\n",
      "'link' # of unique values: 8664\n",
      "\n",
      "% Unique Values per Column\n",
      "'title' % of unique values: 57.7 %\n",
      "'company' % of unique values: 50.66 %\n",
      "'salary' % of unique values: 26.99 %\n",
      "'location' % of unique values: 14.78 %\n",
      "'department' % of unique values: 4.6 %\n",
      "'type' % of unique values: 0.08 %\n",
      "'description' % of unique values: 81.2 %\n",
      "'company_questions' % of unique values: 27.86 %\n",
      "'posted_date' % of unique values: 0.97 %\n",
      "'link' % of unique values: 88.41 %\n"
     ]
    }
   ],
   "source": [
    "def check_nunique_values(df):\n",
    "    # check number of unique values per column\n",
    "    print(\"# Unique Values per Column\")\n",
    "    for col in df.columns:\n",
    "        print(\"'\"+col+\"'\", \"# of unique values:\", df[col].nunique())\n",
    "        \n",
    "    # check % of unique values per column (relative to number of total rows in the dataset)\n",
    "    print(\"\\n% Unique Values per Column\")\n",
    "    for col in df.columns:\n",
    "        print(\"'\"+col+\"'\", \"% of unique values:\", round(df[col].nunique() * 100 / df.shape[0], 2), \"%\")\n",
    "        \n",
    "check_nunique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e88d6-fc2a-4f32-aa18-43a753474b66",
   "metadata": {},
   "source": [
    "Some of our columns have a __large amount of unique values__.\n",
    "\n",
    "The with vast amount of unique values __(>50% of total rows)__.\n",
    "- title\n",
    "- company\n",
    "- description\n",
    "- link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3423f09-458a-47af-a4e3-e1ddb1371a51",
   "metadata": {},
   "source": [
    "Let's start __dealing with the unique values per column.__\n",
    "\n",
    "To reduce the number of unique values, let's apply some NLP methods to each column values.\n",
    "\n",
    "We will start with some basic cleaning that includes:\n",
    "- removing punctuation\n",
    "- removing digits\n",
    "- apply lower case to all letters\n",
    "- removing extra whitespaces\n",
    "\n",
    "To accomplish this, we will implement a __class called NLP__ that will __contain NLP methods/techniques__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b61c0e-6e6e-44a3-be52-9ddcefbd6691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "# class containing our implemented NLP techniques and methods\n",
    "class NLP():\n",
    "    \n",
    "    # remove all punctuation from a word (string)\n",
    "    def remove_punctuation(self, word):\n",
    "        if not isinstance(word, str): return word\n",
    "        return word.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # remove all digits/numbers from a word (string)\n",
    "    def remove_digits(self, word):\n",
    "        if not isinstance(word, str): return word\n",
    "        return re.sub(r'\\d+', '', word)\n",
    "    \n",
    "    # checks if word is a string and returns lower cased\n",
    "    def lower_word(self, word):\n",
    "        if not isinstance(word, str): return word\n",
    "        return word.lower()\n",
    "\n",
    "    # perform basic operations to clean 1 column of a dataframe\n",
    "    def basic_clean_text_column(self, df, colname):\n",
    "        print(\"Basic cleaning on column '\" + colname + \"':\")\n",
    "        nunique = df[colname].nunique()\n",
    "        print(\"# Unique values before cleaning:\", df[colname].nunique())\n",
    "        for value in df[colname].unique():\n",
    "            # save original value to replace later\n",
    "            og_value = value\n",
    "            \n",
    "            # if we are dealing with a null value, don't modify anything\n",
    "            if value is np.nan: continue\n",
    "            \n",
    "            # remove punctuation from the column value\n",
    "            value = self.remove_punctuation(str(value))\n",
    "            \n",
    "            # remove digits from column value\n",
    "            value = self.remove_digits(value)\n",
    "            \n",
    "            # lower case column value\n",
    "            value = self.lower_word(value)\n",
    "            \n",
    "            # word tokenize the column value\n",
    "            word_tokens = word_tokenize(value)\n",
    "            \n",
    "            # update df value in place\n",
    "            df[colname].replace(og_value, ' '.join(word_tokens), inplace=True)\n",
    "        new_nunique = df[colname].nunique()\n",
    "        print(\"# Unique values after cleaning:\", df[colname].nunique())\n",
    "        print(\"% of unique values reduction:\", round(100 - (new_nunique*100/nunique),2), \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6c780-abb2-4a8d-b79a-3a64c2f89fdf",
   "metadata": {},
   "source": [
    "Now that we have implemented a class for our methods,\n",
    "\n",
    "let's go ahead and __apply a basic cleaning on all our columns__.\n",
    "\n",
    "Then, we can __compare values before vs after cleaning__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73deb158-a819-4850-8576-6ddbcc24a1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'title':\n",
      "# Unique values before cleaning: 5655\n",
      "# Unique values after cleaning: 5541\n",
      "% of unique values reduction: 2.02 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>clean title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experienced Support Worker (PPT &amp; CAS)</td>\n",
       "      <td>experienced support worker ppt cas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regional Manager - Inspire@HOME</td>\n",
       "      <td>regional manager inspirehome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family Support Worker</td>\n",
       "      <td>family support worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPS Case Manager</td>\n",
       "      <td>cps case manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intake Worker</td>\n",
       "      <td>intake worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>level support engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>night shift warehouse team leader wanted wethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>casual retail assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>studio assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>junior it support officer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                Experienced Support Worker (PPT & CAS)   \n",
       "1                       Regional Manager - Inspire@HOME   \n",
       "2                                 Family Support Worker   \n",
       "3                                      CPS Case Manager   \n",
       "4                                         Intake Worker   \n",
       "...                                                 ...   \n",
       "9795                         Level 2/3 Support Engineer   \n",
       "9796  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "9797                            Casual Retail Assistant   \n",
       "9798                                   Studio Assistant   \n",
       "9799                          Junior IT Support Officer   \n",
       "\n",
       "                                            clean title  \n",
       "0                    experienced support worker ppt cas  \n",
       "1                          regional manager inspirehome  \n",
       "2                                 family support worker  \n",
       "3                                      cps case manager  \n",
       "4                                         intake worker  \n",
       "...                                                 ...  \n",
       "9795                             level support engineer  \n",
       "9796  night shift warehouse team leader wanted wethe...  \n",
       "9797                            casual retail assistant  \n",
       "9798                                   studio assistant  \n",
       "9799                          junior it support officer  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_and_compare_column(df, colname):\n",
    "    # save raw title data into a new dataframe just to compare before vs after cleaning\n",
    "    df_compare = df[[colname]].copy()\n",
    "\n",
    "    # perform the basic cleaning on the title column\n",
    "    nlp = NLP()\n",
    "    nlp.basic_clean_text_column(df, colname)\n",
    "\n",
    "    # compare before vs after\n",
    "    df_compare[\"clean \"+colname] = df[colname]\n",
    "    display(df_compare)\n",
    "\n",
    "clean_and_compare_column(df, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56efc01-a23d-4b50-ae8a-bc3979da51b6",
   "metadata": {},
   "source": [
    "After this __1st experiment__ of __cleaning the 'title' column__ we notice that we have __reduced the number of unique values by 114__.\n",
    "\n",
    "Which is equivalent of aproximately __2% of the total unique values__, __not a significant reduction__.\n",
    "\n",
    "However, we have considerably clean our raw texts, and this will allow us to apply further NLP techniques that will have better results on reducing the number of unique values.\n",
    "\n",
    "But before getting ahead, let's __apply the same basic cleaning on most of our text columns__ such as:\n",
    "- title\n",
    "- location\n",
    "- department\n",
    "- description\n",
    "- company_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76605134-4666-4978-9972-8697ac556f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'location':\n",
      "# Unique values before cleaning: 1448\n",
      "# Unique values after cleaning: 1448\n",
      "% of unique values reduction: 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>clean location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wagga Wagga, Wagga Wagga &amp; Riverina NSW</td>\n",
       "      <td>wagga wagga wagga wagga riverina nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Launceston, Launceston &amp; North East TAS</td>\n",
       "      <td>launceston launceston north east tas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Townsville, Northern QLD</td>\n",
       "      <td>townsville northern qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nambour, Sunshine Coast QLD</td>\n",
       "      <td>nambour sunshine coast qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Underwood, Brisbane QLD</td>\n",
       "      <td>underwood brisbane qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>sydney nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>wetherill park sydney nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>randwick sydney nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>oxenford gold coast qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>northmead sydney nsw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     location  \\\n",
       "0     Wagga Wagga, Wagga Wagga & Riverina NSW   \n",
       "1     Launceston, Launceston & North East TAS   \n",
       "2                    Townsville, Northern QLD   \n",
       "3                 Nambour, Sunshine Coast QLD   \n",
       "4                     Underwood, Brisbane QLD   \n",
       "...                                       ...   \n",
       "9795                               Sydney NSW   \n",
       "9796               Wetherill Park, Sydney NSW   \n",
       "9797                     Randwick, Sydney NSW   \n",
       "9798                 Oxenford, Gold Coast QLD   \n",
       "9799                    Northmead, Sydney NSW   \n",
       "\n",
       "                            clean location  \n",
       "0     wagga wagga wagga wagga riverina nsw  \n",
       "1     launceston launceston north east tas  \n",
       "2                  townsville northern qld  \n",
       "3               nambour sunshine coast qld  \n",
       "4                   underwood brisbane qld  \n",
       "...                                    ...  \n",
       "9795                            sydney nsw  \n",
       "9796             wetherill park sydney nsw  \n",
       "9797                   randwick sydney nsw  \n",
       "9798               oxenford gold coast qld  \n",
       "9799                  northmead sydney nsw  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'department':\n",
      "# Unique values before cleaning: 451\n",
      "# Unique values after cleaning: 451\n",
      "% of unique values reduction: 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>clean department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aged &amp; Disability Support (Community Services ...</td>\n",
       "      <td>aged disability support community services dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Community Development (Community Services &amp; De...</td>\n",
       "      <td>community development community services devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>help desk it support information communication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>warehousing storage distribution manufacturing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>retail assistants retail consumer products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>pickers packers manufacturing transport logistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>help desk it support information communication...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             department  \\\n",
       "0     Aged & Disability Support (Community Services ...   \n",
       "1     Child Welfare, Youth & Family Services (Commun...   \n",
       "2     Child Welfare, Youth & Family Services (Commun...   \n",
       "3     Community Development (Community Services & De...   \n",
       "4     Child Welfare, Youth & Family Services (Commun...   \n",
       "...                                                 ...   \n",
       "9795  Help Desk & IT Support (Information & Communic...   \n",
       "9796  Warehousing, Storage & Distribution (Manufactu...   \n",
       "9797     Retail Assistants (Retail & Consumer Products)   \n",
       "9798  Pickers & Packers (Manufacturing, Transport & ...   \n",
       "9799  Help Desk & IT Support (Information & Communic...   \n",
       "\n",
       "                                       clean department  \n",
       "0     aged disability support community services dev...  \n",
       "1     child welfare youth family services community ...  \n",
       "2     child welfare youth family services community ...  \n",
       "3     community development community services devel...  \n",
       "4     child welfare youth family services community ...  \n",
       "...                                                 ...  \n",
       "9795  help desk it support information communication...  \n",
       "9796  warehousing storage distribution manufacturing...  \n",
       "9797         retail assistants retail consumer products  \n",
       "9798  pickers packers manufacturing transport logistics  \n",
       "9799  help desk it support information communication...  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'description':\n",
      "# Unique values before cleaning: 7958\n",
      "# Unique values after cleaning: 7928\n",
      "% of unique values reduction: 0.38 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>clean description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>about uswe are an outcome focused ndis service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>catholiccare tasmania is the primary social se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Community Gro Inc is a community-based non-pro...</td>\n",
       "      <td>community gro inc is a communitybased nonprofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a Case Manager for Coastal Supports at Open...</td>\n",
       "      <td>as a case manager for coastal supports at open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>About Us and Our Team Culture   At The Centre ...</td>\n",
       "      <td>about us and our team culture at the centre fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>The opportunityAs part of our exciting growth ...</td>\n",
       "      <td>the opportunityas part of our exciting growth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>Our client is one of Australia's leading Manuf...</td>\n",
       "      <td>our client is one of australias leading manufa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>independent living specialists is a fastgrowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Cendré is a revered e-commerce jewellery brand...</td>\n",
       "      <td>cendré is a revered ecommerce jewellery brand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Parramatta locationWork with a close-knit, exp...</td>\n",
       "      <td>parramatta locationwork with a closeknit exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "0     About usWe are an outcome focused NDIS service...   \n",
       "1     CatholicCare Tasmania is the primary social se...   \n",
       "2     Community Gro Inc is a community-based non-pro...   \n",
       "3     As a Case Manager for Coastal Supports at Open...   \n",
       "4     About Us and Our Team Culture   At The Centre ...   \n",
       "...                                                 ...   \n",
       "9795  The opportunityAs part of our exciting growth ...   \n",
       "9796  Our client is one of Australia's leading Manuf...   \n",
       "9797  Independent Living Specialists is a fast-growi...   \n",
       "9798  Cendré is a revered e-commerce jewellery brand...   \n",
       "9799  Parramatta locationWork with a close-knit, exp...   \n",
       "\n",
       "                                      clean description  \n",
       "0     about uswe are an outcome focused ndis service...  \n",
       "1     catholiccare tasmania is the primary social se...  \n",
       "2     community gro inc is a communitybased nonprofi...  \n",
       "3     as a case manager for coastal supports at open...  \n",
       "4     about us and our team culture at the centre fo...  \n",
       "...                                                 ...  \n",
       "9795  the opportunityas part of our exciting growth ...  \n",
       "9796  our client is one of australias leading manufa...  \n",
       "9797  independent living specialists is a fastgrowin...  \n",
       "9798  cendré is a revered ecommerce jewellery brand ...  \n",
       "9799  parramatta locationwork with a closeknit exper...  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'company_questions':\n",
      "# Unique values before cleaning: 2730\n",
      "# Unique values after cleaning: 2728\n",
      "% of unique values reduction: 0.07 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_questions</th>\n",
       "      <th>clean company_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>do you own or have regular access to a carwhic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>which of the following statements best describ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>which of the following statements best describ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>which of the following statements best describ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>do you have customer service experiencedo you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Do you have demonstrated experience diagnosing...</td>\n",
       "      <td>do you have demonstrated experience diagnosing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      company_questions  \\\n",
       "0     Do you own or have regular access to a car?Whi...   \n",
       "1                                                   NaN   \n",
       "2     Which of the following statements best describ...   \n",
       "3                                                   NaN   \n",
       "4     Which of the following statements best describ...   \n",
       "...                                                 ...   \n",
       "9795  Which of the following statements best describ...   \n",
       "9796                                                NaN   \n",
       "9797  Do you have customer service experience?Do you...   \n",
       "9798                                                NaN   \n",
       "9799  Do you have demonstrated experience diagnosing...   \n",
       "\n",
       "                                clean company_questions  \n",
       "0     do you own or have regular access to a carwhic...  \n",
       "1                                                   NaN  \n",
       "2     which of the following statements best describ...  \n",
       "3                                                   NaN  \n",
       "4     which of the following statements best describ...  \n",
       "...                                                 ...  \n",
       "9795  which of the following statements best describ...  \n",
       "9796                                                NaN  \n",
       "9797  do you have customer service experiencedo you ...  \n",
       "9798                                                NaN  \n",
       "9799  do you have demonstrated experience diagnosing...  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the remaining text columns that we need to perform a basic clean\n",
    "text_cols = ['location', 'department', 'description', 'company_questions']\n",
    "\n",
    "# implement a function to perform the cleaning on these columns\n",
    "def clean_and_compare_columns(df, cols):\n",
    "    for colname in cols:\n",
    "        clean_and_compare_column(df, colname)\n",
    "\n",
    "# call the implemented function\n",
    "clean_and_compare_columns(df, text_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a36db8-4d5f-45a3-8114-86353f62b8ee",
   "metadata": {},
   "source": [
    "Let's take a look to the entire __dataframe__ in the __current clean version__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19515e7e-9668-4c0c-ab01-e785e61810ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experienced support worker ppt cas</td>\n",
       "      <td>Ability Gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>wagga wagga wagga wagga riverina nsw</td>\n",
       "      <td>aged disability support community services dev...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>about uswe are an outcome focused ndis service...</td>\n",
       "      <td>do you own or have regular access to a carwhic...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regional manager inspirehome</td>\n",
       "      <td>CatholicCare Tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>launceston launceston north east tas</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>catholiccare tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family support worker</td>\n",
       "      <td>Community Gro</td>\n",
       "      <td>$40 – $44 per hour</td>\n",
       "      <td>townsville northern qld</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>community gro inc is a communitybased nonprofi...</td>\n",
       "      <td>which of the following statements best describ...</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>https://www.seek.com.au/job/73832771?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cps case manager</td>\n",
       "      <td>Open Minds</td>\n",
       "      <td>$82k – 84k + super + salary packaging + benefits</td>\n",
       "      <td>nambour sunshine coast qld</td>\n",
       "      <td>community development community services devel...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>as a case manager for coastal supports at open...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901240?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intake worker</td>\n",
       "      <td>The Centre for Women &amp; Co.</td>\n",
       "      <td>$41 – $42 per hour</td>\n",
       "      <td>underwood brisbane qld</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>about us and our team culture at the centre fo...</td>\n",
       "      <td>which of the following statements best describ...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73861002?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                     company  \\\n",
       "0  experienced support worker ppt cas             Ability Gateway   \n",
       "1        regional manager inspirehome       CatholicCare Tasmania   \n",
       "2               family support worker               Community Gro   \n",
       "3                    cps case manager                  Open Minds   \n",
       "4                       intake worker  The Centre for Women & Co.   \n",
       "\n",
       "                                             salary  \\\n",
       "0                             $35.50 per hour [PPT]   \n",
       "1                                               NaN   \n",
       "2                                $40 – $44 per hour   \n",
       "3  $82k – 84k + super + salary packaging + benefits   \n",
       "4                                $41 – $42 per hour   \n",
       "\n",
       "                               location  \\\n",
       "0  wagga wagga wagga wagga riverina nsw   \n",
       "1  launceston launceston north east tas   \n",
       "2               townsville northern qld   \n",
       "3            nambour sunshine coast qld   \n",
       "4                underwood brisbane qld   \n",
       "\n",
       "                                          department       type  \\\n",
       "0  aged disability support community services dev...  Part time   \n",
       "1  child welfare youth family services community ...  Full time   \n",
       "2  child welfare youth family services community ...  Full time   \n",
       "3  community development community services devel...  Full time   \n",
       "4  child welfare youth family services community ...  Full time   \n",
       "\n",
       "                                         description  \\\n",
       "0  about uswe are an outcome focused ndis service...   \n",
       "1  catholiccare tasmania is the primary social se...   \n",
       "2  community gro inc is a communitybased nonprofi...   \n",
       "3  as a case manager for coastal supports at open...   \n",
       "4  about us and our team culture at the centre fo...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  do you own or have regular access to a carwhic...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "2  which of the following statements best describ...  2024-02-19   \n",
       "3                                                NaN  2024-02-21   \n",
       "4  which of the following statements best describ...  2024-02-20   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...  \n",
       "2  https://www.seek.com.au/job/73832771?type=stan...  \n",
       "3  https://www.seek.com.au/job/73901240?type=stan...  \n",
       "4  https://www.seek.com.au/job/73861002?type=stan...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display our current dataframe version\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85414198-d252-42e7-aa85-323d9c671c52",
   "metadata": {},
   "source": [
    "We have seen __lots of stopwords accross our dataset__.\n",
    "\n",
    "Our next step for cleaning is to remove all those stopwords.\n",
    "\n",
    "However, we must __pay attention to certain words that have important meaning and at the same time are considered stopwords__.\n",
    "\n",
    "- __Example:__ The most common meaning of __\"it\"__ is considered a stopword. However, \"it\" in job postings may refer to \"Information Technologies\".\n",
    "\n",
    "Let's start by identifying words of 1, 2, and 3 characters long, so we can __identify which ones to remove, and which ones to keep__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7fdc83-696a-4b3a-b235-05da92f397a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words of length 1 to 3 on column 'title'\n",
      "- Words Length 1\n",
      "['a', 'd', 'f', 'i', 'k', 'l', 'm', 'n', 'p', 's', 't', 'v', 'w', 'x', 'y', '–', '’', '💡', '🤝']\n",
      "- Words Length 2\n",
      "['ah', 'ai', 'am', 'an', 'ao', 'ap', 'ar', 'as', 'at', 'au', 'av', 'ba', 'bb', 'bi', 'bp', 'ca', 'cc', 'ci', 'co', 'cx', 'dc', 'do', 'ds', 'ea', 'el', 'er', 'fm', 'fq', 'ft', 'gc', 'gm', 'go', 'gp', 'hc', 'hm', 'hr', 'ic', 'in', 'it', 'iv', 'ld', 'le', 'lf', 'lo', 'ma', 'mc', 'md', 'mq', 'mr', 'ms', 'mt', 'my', 'nd', 'no', 'nt', 'od', 'of', 'on', 'oo', 'or', 'ot', 'pa', 'pc', 'ph', 'pm', 'po', 'pt', 'pw', 'px', 'qa', 'qc', 'rd', 're', 'rn', 'sa', 'sc', 'sr', 'st', 'sw', 'to', 'tq', 'up', 'us', 'vp', 'wa', 'we', 'yr', '⚽️']\n",
      "- Words Length 3\n",
      "['abn', 'acm', 'act', 'age', 'ags', 'aid', 'ain', 'air', 'ald', 'alh', 'ali', 'all', 'ame', 'and', 'anz', 'aod', 'app', 'aps', 'apy', 'arc', 'are', 'aso', 'asx', 'atm', 'aus', 'aws', 'bar', 'bas', 'bay', 'bdm', 'bft', 'bgs', 'bid', 'bms', 'bom', 'box', 'bus', 'bws', 'cad', 'car', 'cas', 'cbd', 'ccs', 'cdc', 'ceo', 'cfo', 'cmt', 'cmy', 'cnc', 'cns', 'coo', 'cpc', 'cps', 'crk', 'crm', 'csl', 'ctp', 'daf', 'day', 'dev', 'dfo', 'dfv', 'div', 'dna', 'dog', 'dry', 'due', 'eca', 'ecm', 'egm', 'eho', 'ehs', 'elc', 'elm', 'emu', 'end', 'eoi', 'esd', 'esg', 'eso', 'euc', 'exp', 'far', 'fit', 'fix', 'fld', 'foi', 'fom', 'for', 'fpa', 'ftc', 'fte', 'fun', 'gap', 'gas', 'gcf', 'get', 'gin', 'gis', 'gmp', 'gpc', 'gym', 'hbc', 'hcp', 'her', 'his', 'hsp', 'hub', 'icp', 'ict', 'iga', 'imc', 'ims', 'inc', 'ion', 'isa', 'iso', 'itc', 'its', 'itt', 'ivf', 'jay', 'jmf', 'job', 'key', 'kit', 'lab', 'law', 'llc', 'lms', 'ltd', 'lvl', 'mcv', 'mep', 'mgr', 'mid', 'moe', 'msp', 'mth', 'net', 'new', 'nfp', 'ngs', 'nmr', 'nnw', 'non', 'now', 'nsw', 'nth', 'num', 'occ', 'off', 'one', 'ops', 'org', 'otc', 'ote', 'our', 'out', 'pae', 'pay', 'pcp', 'per', 'pet', 'phd', 'pmo', 'png', 'pos', 'ppt', 'pqe', 'pre', 'psu', 'pts', 'pty', 'qld', 'qsr', 'rab', 'ras', 'ray', 'rda', 'rep', 'rpd', 'rto', 'sap', 'sea', 'seo', 'ses', 'set', 'sil', 'sme', 'smp', 'sor', 'spa', 'spt', 'stp', 'sub', 'syd', 'tas', 'tax', 'tcs', 'tea', 'the', 'tmp', 'top', 'trc', 'try', 'ttw', 'two', 'uni', 'ute', 'van', 'vce', 'veg', 'vic', 'vps', 'web', 'wet', 'wfa', 'wfh', 'whs', 'whv', 'wmc', 'woy', 'yha', 'you']\n"
     ]
    }
   ],
   "source": [
    "# return a list of lists, each list will contain the words of length 1, 2, 3... n\n",
    "def identify_words_len_1_to_n(df, colname, n):\n",
    "    # set n number of empty lists\n",
    "    words = [[] for _ in range(n)]\n",
    "    \n",
    "    # loop through unique values of the column\n",
    "    for value in df[colname].unique():\n",
    "        # if it's not a string, go to the next value\n",
    "        if not isinstance(value, str): continue\n",
    "        \n",
    "        # tokenize the value, loop through the words, if the word length its in range, add them to corresponding list\n",
    "        tokens = word_tokenize(value)\n",
    "        for word in tokens:\n",
    "            if len(word) <= n:\n",
    "                words[len(word)-1].append(word)\n",
    "                \n",
    "    # delete repeated values in the lists and sort them\n",
    "    words_len_1_to_n = [sorted(list(set(words_sublist))) for words_sublist in words]\n",
    "    \n",
    "    # print the results (each list)\n",
    "    print(\"Words of length 1 to\", n, \"on column '\"+colname+\"'\")\n",
    "    for i in range(n):\n",
    "        print(\"- Words Length\", i+1)\n",
    "        print(words_len_1_to_n[i])\n",
    "    return words_len_1_to_n\n",
    "\n",
    "words_len_1_to_3 = identify_words_len_1_to_n(df, 'title', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee8744-1d68-4a7c-8a6a-9a03916e76d3",
   "metadata": {},
   "source": [
    "For our column title all words length 1 need to be removed, as they don't bring any value to our analysis.\n",
    "\n",
    "The only 1-length string that will not be removed is the apostrophe to keep word consistency.\n",
    "- __’__ : apostrophe\n",
    "\n",
    "From our 2 length words, we will remove most of them except for the following common job accronyms:\n",
    "- __hr__ : Human Resources\n",
    "- __it__: Information Technology\n",
    "\n",
    "From the 3 length words, again we will remove most of them except for the following:\n",
    "- __ceo__: Chief Executive Officer\n",
    "- __cfo__: Chief Financial Officer\n",
    "- __aws__: Amazon Web Services\n",
    "- __pmo__: Project Management Office\n",
    "- __pcp__: Primary Care Physician\n",
    "- __crm__: Customer Relationship Management\n",
    "- __sap__: System Applications (ERP leader)\n",
    "- __app__: application\n",
    "- __dev__: developer\n",
    "- __lab__: laboratory\n",
    "- __web__: internet\n",
    "- __law__: self-explanatory\n",
    "\n",
    "Let's perform the same operation with the rest of the text columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "931825ec-bca3-4fa8-9704-a2034083630c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns: ['title', 'location', 'department', 'description', 'company_questions']\n",
      "Words max length: [3, 3, 3, 2, 3]\n",
      "\n",
      "Words of length 1 to 3 on column 'title'\n",
      "- Words Length 1\n",
      "['a', 'd', 'f', 'i', 'k', 'l', 'm', 'n', 'p', 's', 't', 'v', 'w', 'x', 'y', '–', '’', '💡', '🤝']\n",
      "- Words Length 2\n",
      "['ah', 'ai', 'am', 'an', 'ao', 'ap', 'ar', 'as', 'at', 'au', 'av', 'ba', 'bb', 'bi', 'bp', 'ca', 'cc', 'ci', 'co', 'cx', 'dc', 'do', 'ds', 'ea', 'el', 'er', 'fm', 'fq', 'ft', 'gc', 'gm', 'go', 'gp', 'hc', 'hm', 'hr', 'ic', 'in', 'it', 'iv', 'ld', 'le', 'lf', 'lo', 'ma', 'mc', 'md', 'mq', 'mr', 'ms', 'mt', 'my', 'nd', 'no', 'nt', 'od', 'of', 'on', 'oo', 'or', 'ot', 'pa', 'pc', 'ph', 'pm', 'po', 'pt', 'pw', 'px', 'qa', 'qc', 'rd', 're', 'rn', 'sa', 'sc', 'sr', 'st', 'sw', 'to', 'tq', 'up', 'us', 'vp', 'wa', 'we', 'yr', '⚽️']\n",
      "- Words Length 3\n",
      "['abn', 'acm', 'act', 'age', 'ags', 'aid', 'ain', 'air', 'ald', 'alh', 'ali', 'all', 'ame', 'and', 'anz', 'aod', 'app', 'aps', 'apy', 'arc', 'are', 'aso', 'asx', 'atm', 'aus', 'aws', 'bar', 'bas', 'bay', 'bdm', 'bft', 'bgs', 'bid', 'bms', 'bom', 'box', 'bus', 'bws', 'cad', 'car', 'cas', 'cbd', 'ccs', 'cdc', 'ceo', 'cfo', 'cmt', 'cmy', 'cnc', 'cns', 'coo', 'cpc', 'cps', 'crk', 'crm', 'csl', 'ctp', 'daf', 'day', 'dev', 'dfo', 'dfv', 'div', 'dna', 'dog', 'dry', 'due', 'eca', 'ecm', 'egm', 'eho', 'ehs', 'elc', 'elm', 'emu', 'end', 'eoi', 'esd', 'esg', 'eso', 'euc', 'exp', 'far', 'fit', 'fix', 'fld', 'foi', 'fom', 'for', 'fpa', 'ftc', 'fte', 'fun', 'gap', 'gas', 'gcf', 'get', 'gin', 'gis', 'gmp', 'gpc', 'gym', 'hbc', 'hcp', 'her', 'his', 'hsp', 'hub', 'icp', 'ict', 'iga', 'imc', 'ims', 'inc', 'ion', 'isa', 'iso', 'itc', 'its', 'itt', 'ivf', 'jay', 'jmf', 'job', 'key', 'kit', 'lab', 'law', 'llc', 'lms', 'ltd', 'lvl', 'mcv', 'mep', 'mgr', 'mid', 'moe', 'msp', 'mth', 'net', 'new', 'nfp', 'ngs', 'nmr', 'nnw', 'non', 'now', 'nsw', 'nth', 'num', 'occ', 'off', 'one', 'ops', 'org', 'otc', 'ote', 'our', 'out', 'pae', 'pay', 'pcp', 'per', 'pet', 'phd', 'pmo', 'png', 'pos', 'ppt', 'pqe', 'pre', 'psu', 'pts', 'pty', 'qld', 'qsr', 'rab', 'ras', 'ray', 'rda', 'rep', 'rpd', 'rto', 'sap', 'sea', 'seo', 'ses', 'set', 'sil', 'sme', 'smp', 'sor', 'spa', 'spt', 'stp', 'sub', 'syd', 'tas', 'tax', 'tcs', 'tea', 'the', 'tmp', 'top', 'trc', 'try', 'ttw', 'two', 'uni', 'ute', 'van', 'vce', 'veg', 'vic', 'vps', 'web', 'wet', 'wfa', 'wfh', 'whs', 'whv', 'wmc', 'woy', 'yha', 'you']\n",
      "\n",
      "\n",
      "Words of length 1 to 3 on column 'location'\n",
      "- Words Length 1\n",
      "['m']\n",
      "- Words Length 2\n",
      "['mt', 'nt', 'of', 'sa', 'st', 'wa']\n",
      "- Words Length 3\n",
      "['act', 'ayr', 'bar', 'bay', 'bli', 'box', 'dee', 'dry', 'emu', 'end', 'far', 'gap', 'hay', 'hom', 'isa', 'kew', 'koo', 'mid', 'moe', 'new', 'nsw', 'oak', 'old', 'qld', 'red', 'rup', 'tas', 'the', 'tom', 'two', 'vic', 'wee', 'why', 'woy']\n",
      "\n",
      "\n",
      "Words of length 1 to 3 on column 'department'\n",
      "- Words Length 1\n",
      "[]\n",
      "- Words Length 2\n",
      "['ae', 'ea', 'hr', 'it', 'md', 'ot', 'pa']\n",
      "- Words Length 3\n",
      "['ceo', 'coo', 'crm', 'icu', 'law', 'new', 'pre', 'tax', 'web']\n",
      "\n",
      "\n",
      "Words of length 1 to 2 on column 'description'\n",
      "- Words Length 1\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '©', '\\xad', '®', '°', '·', '»', '½', 'ø', '\\u200b', '–', '—', '‘', '’', '“', '”', '•', '…', '‼', '⁄', '€', '→', '⏳', '▸', '●', '☒', '✅', '✔', '✨', '⭐', '\\uf0d8', '�', '𝗮', '🌈', '🌍', '🌐', '🌞', '🌟', '🌱', '🌳', '🌴', '🌻', '🎁', '🎉', '🎥', '🎨', '🎯', '🏆', '🏊', '🏐', '🐦', '👉', '👍', '👪', '💡', '💪', '💰', '💲', '💵', '💻', '💼', '📃', '📈', '📊', '📍', '📝', '📞', '📢', '📧', '📱', '📸', '🔍', '🔝', '🔴', '😄', '😉', '😊', '😍', '🚀', '🚗', '🟡', '🤔', '🤝', '🤞', '🥰', '🩺']\n",
      "- Words Length 2\n",
      "['aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'ar', 'as', 'at', 'au', 'av', 'aw', 'ax', 'az', 'a•', 'bb', 'bc', 'bd', 'be', 'bf', 'bg', 'bi', 'bk', 'bl', 'bm', 'bn', 'bp', 'bs', 'bt', 'bu', 'bv', 'bw', 'bx', 'by', 'ca', 'cc', 'ce', 'cf', 'ch', 'ci', 'ck', 'cl', 'cm', 'cn', 'co', 'cq', 'cs', 'ct', 'cv', 'cw', 'cx', 'cy', 'da', 'db', 'dc', 'dd', 'de', 'df', 'dg', 'di', 'dj', 'dk', 'dm', 'dn', 'do', 'dp', 'dr', 'ds', 'dt', 'dv', 'dw', 'ea', 'eb', 'ec', 'ed', 'ee', 'ef', 'eg', 'ei', 'el', 'em', 'en', 'eo', 'ep', 'eq', 'er', 'es', 'et', 'eu', 'ev', 'ex', 'ey', 'fa', 'fb', 'fc', 'fe', 'ff', 'fg', 'fi', 'fm', 'fo', 'fp', 'fq', 'fs', 'ft', 'fx', 'fy', 'ga', 'gb', 'gc', 'gd', 'ge', 'gf', 'gi', 'gk', 'gl', 'gm', 'go', 'gp', 'gq', 'gs', 'gt', 'gu', 'gv', 'gw', 'gx', 'ha', 'hb', 'hc', 'hd', 'he', 'hg', 'hh', 'hi', 'hk', 'hl', 'ho', 'hp', 'hq', 'hr', 'hs', 'ht', 'hv', 'hw', 'ia', 'ib', 'ic', 'id', 'ie', 'if', 'ig', 'ii', 'im', 'in', 'io', 'ip', 'iq', 'ir', 'is', 'it', 'iv', 'iw', 'iy', 'jb', 'jd', 'jg', 'jh', 'jj', 'jk', 'jn', 'jo', 'jp', 'jr', 'js', 'jv', 'kb', 'kc', 'kd', 'ke', 'kf', 'kg', 'kh', 'kj', 'kk', 'km', 'kp', 'kt', 'kw', 'la', 'lb', 'lc', 'ld', 'le', 'lf', 'lg', 'li', 'lj', 'lk', 'll', 'ln', 'lo', 'lp', 'lr', 'lv', 'ly', 'ma', 'mb', 'mc', 'md', 'me', 'mf', 'mg', 'mj', 'mk', 'ml', 'mm', 'mo', 'mp', 'mq', 'mr', 'ms', 'mt', 'mv', 'mw', 'my', 'na', 'nb', 'nc', 'nd', 'ne', 'ng', 'nh', 'ni', 'no', 'np', 'nq', 'nt', 'nv', 'nw', 'nx', 'ny', 'nz', 'oc', 'od', 'oe', 'of', 'og', 'oh', 'ok', 'om', 'on', 'op', 'oq', 'or', 'os', 'ot', 'oz', 'pa', 'pc', 'pd', 'pe', 'pf', 'pg', 'ph', 'pi', 'pl', 'pm', 'pn', 'po', 'pp', 'pq', 'pr', 'ps', 'pt', 'pv', 'pw', 'px', 'qa', 'qb', 'qc', 'qe', 'qh', 'qm', 'qr', 'qs', 'qv', 'ra', 'rc', 'rd', 're', 'rf', 'rg', 'rh', 'ri', 'rn', 'ro', 'rp', 'rs', 'rv', 'rw', 'sa', 'sc', 'sd', 'se', 'sf', 'sg', 'si', 'sm', 'sn', 'so', 'sp', 'sq', 'sr', 'ss', 'st', 'sw', 's®', 's•', 'ta', 'tb', 'tc', 'td', 'te', 'th', 'ti', 'tj', 'tm', 'to', 'tq', 'ts', 'tt', 'tv', 'ty', 'tz', 'ua', 'uc', 'ud', 'uf', 'ui', 'uk', 'ul', 'um', 'un', 'up', 'uq', 'us', 'uu', 'uv', 'uw', 'ux', 'va', 'vc', 've', 'vm', 'vp', 'vr', 'vs', 'vu', 'vv', 'vw', 'vx', 'wa', 'wc', 'wd', 'we', 'wh', 'wj', 'wk', 'wl', 'wo', 'wr', 'ws', 'ww', 'wx', 'xg', 'xi', 'xm', 'xo', 'xp', 'xu', 'xx', 'ya', 'yd', 'yo', 'yr', 'ys', 'yu', 'za', 'zd', 'zp', 'zs', '£k', '\\xad–', '°c', 'ºc', '˚c', '\\u200ba', '–a', '•a', '…a', '\\u2063\\u2063', '◼️', '⚙️', '⚫️', '✅a', '✔️', '\\ufeffa', '\\ufeff\\ufeff', '𝗕𝗲', '𝗪𝗲', '𝘁𝗼', '𝘄𝗲', '🌟🔒', '🍌🍌', '👁️', '💸✅', '📲✨', '🔥🔥', '🙌🏼', '🚀✨', '🚀📍', '🤝🏼', '🤩🙌']\n",
      "\n",
      "\n",
      "Words of length 1 to 3 on column 'company_questions'\n",
      "- Words Length 1\n",
      "['a', 'c', 'i', 'p', 's', 'x', '–', '’']\n",
      "- Words Length 2\n",
      "['ad', 'am', 'an', 'as', 'at', 'ax', 'bb', 'be', 'by', 'ca', 'cg', 'ct', 'da', 'do', 'eg', 'hc', 'he', 'hr', 'ie', 'if', 'ii', 'in', 'is', 'it', 'iv', 'kg', 'me', 'mr', 'my', 'no', 'nv', 'nz', 'of', 'on', 'or', 'oz', 'pc', 'pm', 'qa', 'qc', 'rf', 'rg', 'so', 'th', 'to', 'up', 'us', 'wa', 'wd', 'we']\n",
      "- Words Length 3\n",
      "['aat', 'act', 'ads', 'aid', 'all', 'and', 'any', 'are', 'ask', 'bar', 'bas', 'bio', 'but', 'cad', 'can', 'car', 'cbd', 'cms', 'cpa', 'crm', 'css', 'day', 'did', 'dns', 'dot', 'end', 'etc', 'ezi', 'far', 'few', 'fit', 'for', 'gas', 'get', 'gmp', 'got', 'gym', 'had', 'has', 'hoc', 'how', 'hrs', 'hub', 'ict', 'iii', 'iso', 'its', 'ivf', 'job', 'key', 'law', 'lcs', 'led', 'let', 'max', 'may', 'mid', 'mlg', 'msp', 'naa', 'ner', 'new', 'not', 'now', 'npc', 'ntt', 'off', 'oil', 'one', 'ote', 'our', 'out', 'own', 'pay', 'per', 'pet', 'pmi', 'pms', 'pos', 'ppe', 'pre', 'ptc', 'put', 'qld', 'rcg', 'red', 'rhl', 'rsa', 'run', 'sap', 'say', 'see', 'sem', 'seo', 'set', 'shy', 'sub', 'tae', 'tax', 'tga', 'the', 'tot', 'tpb', 'tss', 'two', 'use', 'vic', 'vis', 'was', 'way', 'web', 'wed', 'wfh', 'who', 'why', 'wwc', 'yes', 'you']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def identify_words_len_1_to_n_columns(df, text_columns, ns):\n",
    "    # loop through the specified columns and identify the words of length 1 to n\n",
    "    words_per_col = []\n",
    "    for i, colname in enumerate(text_columns):\n",
    "        words_per_col.append(identify_words_len_1_to_n(df, colname, ns[i]))\n",
    "        print(\"\\n\")\n",
    "    return words_per_col\n",
    "\n",
    "# define the word lengths per text column\n",
    "text_cols = ['title', 'location', 'department', 'description', 'company_questions']\n",
    "word_max_lens = [3, 3, 3, 2, 3]\n",
    "print(\"Text columns:\", text_cols, end='\\n')\n",
    "print(\"Words max length:\", word_max_lens, end='\\n\\n')\n",
    "words_per_col = identify_words_len_1_to_n_columns(df, text_cols, word_max_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca5431-4393-4836-9162-022294df3078",
   "metadata": {},
   "source": [
    "Now that we have identified more words to remove, let's __implement a function that removes all stopwords__ on top of the extra ones.\n",
    "\n",
    "Let's also keep in mind the __list of values that should not be removed__ (from the same analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d19419-9f71-491b-94ad-a9b50f0599ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import flatten # convert nested list into 1D list\n",
    "\n",
    "def set_additional_stopwords(words_per_col):\n",
    "    # set our additional stopwords making use of the identified 1 to 3 length words for each column\n",
    "    additionals = []\n",
    "    for column_words in words_per_col:\n",
    "        # make sure we only have unique values by using set\n",
    "        additionals.append(list(set(flatten(column_words))))\n",
    "    return additionals\n",
    "\n",
    "additionals = set_additional_stopwords(words_per_col) # pass our list of lists defined in the previous code block\n",
    "\n",
    "# set the exceptions manually based on our word length analysis\n",
    "exceptions = ['’', 'hr', 'it', 'ceo', 'cfo', 'aws', 'pmo', 'pcp', 'crm', 'sap', 'app', 'dev', 'lab', 'web', 'law']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9927e49-5f19-4935-a839-952683b4c775",
   "metadata": {},
   "source": [
    "Now let's __implement a new class that stores our stopwords removal methods__.\n",
    "\n",
    "We will use this class to perform the stopwords removal __taking into account our additional stopwords and exceptions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f8d54a3-735f-44bf-ade3-76d45eacc377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing stopwords on column 'title'\n",
      "# Unique values with stopwords: 5541\n",
      "# Unique values without stopwords: 5398\n",
      "% of unique values reduction: 2.58 %\n",
      "\n",
      "Removing stopwords on column 'location'\n",
      "# Unique values with stopwords: 1448\n",
      "# Unique values without stopwords: 1439\n",
      "% of unique values reduction: 0.62 %\n",
      "\n",
      "Removing stopwords on column 'department'\n",
      "# Unique values with stopwords: 451\n",
      "# Unique values without stopwords: 449\n",
      "% of unique values reduction: 0.44 %\n",
      "\n",
      "Removing stopwords on column 'description'\n",
      "# Unique values with stopwords: 7928\n",
      "# Unique values without stopwords: 7927\n",
      "% of unique values reduction: 0.01 %\n",
      "\n",
      "Removing stopwords on column 'company_questions'\n",
      "# Unique values with stopwords: 2728\n",
      "# Unique values without stopwords: 2728\n",
      "% of unique values reduction: 0.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NLP_stopwords():\n",
    "    \n",
    "    def remove_stopwords_columns(self, df, colnames, additionals=[], exceptions=[]):\n",
    "        if additionals == []:\n",
    "            additionals = [[] for _ in range(len(colnameS))]\n",
    "        if len(colnames) != len(additionals):\n",
    "            raise Exception(\"Column names length must be equal to the additional stop words.\")\n",
    "\n",
    "        # remove stopwords on specified columns\n",
    "        for i, colname in enumerate(colnames):\n",
    "            self.remove_stopwords_column(df, colname, additionals[i], exceptions)\n",
    "\n",
    "    def remove_stopwords_column(self, df, colname, additional=[], exceptions=[]):\n",
    "        print(\"Removing stopwords on column '\" + colname + \"'\")\n",
    "        nunique = df[colname].nunique()\n",
    "        print(\"# Unique values with stopwords:\", df[colname].nunique())        \n",
    "        \n",
    "        # loop through unique values of the column\n",
    "        for value in df[colname].unique():\n",
    "            # make sure the value is a string\n",
    "            if not isinstance(value, str): continue\n",
    "            \n",
    "            # tokenize the unique column value\n",
    "            tokens = word_tokenize(value)\n",
    "\n",
    "            # remove stopwords\n",
    "            self.remove_stopwords_tokens(tokens, additional, exceptions)\n",
    "\n",
    "            # update df value in place\n",
    "            df[colname].replace(value, ' '.join(tokens), inplace=True)\n",
    "        \n",
    "        new_nunique = df[colname].nunique()\n",
    "        print(\"# Unique values without stopwords:\", df[colname].nunique())\n",
    "        print(\"% of unique values reduction:\", round(100 - (new_nunique*100/nunique),2), \"%\", end=\"\\n\\n\")\n",
    "\n",
    "    def remove_stopwords_tokens(self, tokens, additional=[], exceptions=[]):\n",
    "        # remove stopwords on a list of word tokens\n",
    "        i = 0\n",
    "        # add the additional parameter stopwords\n",
    "        total_stopwords = stopwords.words('english') + additional\n",
    "        while i < len(tokens):\n",
    "            word = tokens[i]\n",
    "            # if the word is in exceptions, don't remove it\n",
    "            if word in total_stopwords and word not in exceptions:\n",
    "                tokens.pop(i)\n",
    "                i -= 1\n",
    "            i += 1\n",
    "\n",
    "nlp = NLP_stopwords()\n",
    "nlp.remove_stopwords_columns(df, text_cols, additionals, exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d1134-6300-4bd4-abf8-cac16ab542af",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's __find the most frequent bigrams and trigrams__ for each column.\n",
    "\n",
    "Once again, we will __define a third NLP class to store our new implemented methods__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f51377e-0e9f-4a0b-8503-e7f015886c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 unigrams of column 'title':\n",
      "[('manager', 1649), ('officer', 1274), ('assistant', 1045), ('support', 590), ('sales', 515), ('engineer', 430), ('coordinator', 423), ('administration', 422), ('senior', 410), ('accountant', 350)]\n",
      "\n",
      "Top 10 bigrams of column 'title':\n",
      "[(('property', 'manager'), 199), (('support', 'officer'), 167), (('general', 'manager'), 153), (('administration', 'officer'), 142), (('administration', 'assistant'), 141), (('people', 'culture'), 138), (('business', 'partner'), 138), (('customer', 'service'), 119), (('part', 'time'), 116), (('human', 'resources'), 115)]\n",
      "\n",
      "Top 10 trigrams of column 'title':\n",
      "[(('chief', 'executive', 'officer'), 77), (('accounts', 'payable', 'officer'), 73), (('hr', 'business', 'partner'), 46), (('business', 'development', 'manager'), 45), (('it', 'support', 'officer'), 44), (('real', 'estate', 'sales'), 44), (('administration', 'assistant', 'administration'), 36), (('retail', 'sales', 'assistant'), 36), (('property', 'manager', 'property'), 33), (('chief', 'financial', 'officer'), 33)]\n",
      "\n",
      "-----------------------------------\n",
      "Top 10 unigrams of column 'location':\n",
      "[('sydney', 2287), ('melbourne', 1793), ('brisbane', 1372), ('coast', 1130), ('perth', 778), ('north', 566), ('west', 473), ('south', 464), ('adelaide', 455), ('newcastle', 340)]\n",
      "\n",
      "Top 10 bigrams of column 'location':\n",
      "[(('gold', 'coast'), 314), (('sydney', 'sydney'), 271), (('newcastle', 'maitland'), 237), (('maitland', 'hunter'), 237), (('melbourne', 'melbourne'), 199), (('south', 'west'), 176), (('sunshine', 'coast'), 167), (('melbourne', 'sydney'), 167), (('sydney', 'melbourne'), 153), (('west', 'coast'), 136)]\n",
      "\n",
      "Top 10 trigrams of column 'location':\n",
      "[(('newcastle', 'maitland', 'hunter'), 237), (('south', 'west', 'coast'), 136), (('wollongong', 'illawarra', 'south'), 116), (('illawarra', 'south', 'coast'), 116), (('toowoomba', 'darling', 'downs'), 101), (('newcastle', 'newcastle', 'maitland'), 100), (('gosford', 'central', 'coast'), 98), (('toowoomba', 'toowoomba', 'darling'), 76), (('geelong', 'south', 'west'), 76), (('rockhampton', 'capricorn', 'coast'), 74)]\n",
      "\n",
      "-----------------------------------\n",
      "Top 10 unigrams of column 'department':\n",
      "[('management', 1723), ('services', 1273), ('accounting', 1212), ('administration', 1055), ('support', 1050), ('technology', 1007), ('retail', 971), ('engineering', 958), ('property', 888), ('assistants', 853)]\n",
      "\n",
      "Top 10 bigrams of column 'department':\n",
      "[(('manufacturing', 'transport'), 732), (('transport', 'logistics'), 728), (('government', 'defence'), 674), (('administration', 'office'), 648), (('information', 'communication'), 628), (('retail', 'consumer'), 564), (('consumer', 'products'), 564), (('community', 'services'), 562), (('real', 'estate'), 562), (('ceo', 'general'), 556)]\n",
      "\n",
      "Top 10 trigrams of column 'department':\n",
      "[(('manufacturing', 'transport', 'logistics'), 728), (('retail', 'consumer', 'products'), 564), (('administration', 'office', 'support'), 553), (('information', 'communication', 'technology'), 549), (('real', 'estate', 'property'), 544), (('community', 'services', 'development'), 521), (('ceo', 'general', 'management'), 514), (('human', 'resources', 'recruitment'), 496), (('administrative', 'assistants', 'administration'), 453), (('assistants', 'administration', 'office'), 453)]\n",
      "\n",
      "-----------------------------------\n",
      "Top 10 unigrams of column 'description':\n",
      "[('team', 23626), ('work', 22973), ('experience', 19887), ('role', 19630), ('’', 15821), ('support', 15059), ('people', 14015), ('skills', 13635), ('management', 12775), ('working', 12415)]\n",
      "\n",
      "Top 10 bigrams of column 'description':\n",
      "[(('customer', 'service'), 3174), (('email', 'protected'), 2955), (('communication', 'skills'), 2562), (('cover', 'letter'), 2330), (('ability', 'work'), 1914), (('torres', 'strait'), 1730), (('attention', 'detail'), 1673), (('skills', 'ability'), 1638), (('please', 'contact'), 1636), (('strait', 'islander'), 1577)]\n",
      "\n",
      "Top 10 trigrams of column 'description':\n",
      "[(('torres', 'strait', 'islander'), 1570), (('aboriginal', 'torres', 'strait'), 1508), (('equal', 'opportunity', 'employer'), 995), (('email', 'email', 'protected'), 785), (('resume', 'cover', 'letter'), 773), (('employee', 'assistance', 'program'), 655), (('written', 'verbal', 'communication'), 611), (('strait', 'islander', 'people'), 608), (('children', 'young', 'people'), 597), (('please', 'click', 'apply'), 507)]\n",
      "\n",
      "-----------------------------------\n",
      "Top 10 unigrams of column 'company_questions':\n",
      "[('following', 5624), ('experience', 5289), ('work', 4618), ('best', 4463), ('describes', 4453), ('statements', 4444), ('right', 4367), ('many', 3844), ('years', 3821), ('current', 2319)]\n",
      "\n",
      "Top 10 bigrams of column 'company_questions':\n",
      "[(('best', 'describes'), 4451), (('statements', 'best'), 4437), (('following', 'statements'), 4434), (('right', 'work'), 4364), (('describes', 'right'), 4352), (('many', 'years'), 3814), (('years', 'experience'), 3103), (('work', 'australiahow'), 2045), (('australiahow', 'many'), 1989), (('expected', 'annual'), 969)]\n",
      "\n",
      "Top 10 trigrams of column 'company_questions':\n",
      "[(('statements', 'best', 'describes'), 4437), (('following', 'statements', 'best'), 4434), (('best', 'describes', 'right'), 4352), (('describes', 'right', 'work'), 4352), (('many', 'years', 'experience'), 3102), (('right', 'work', 'australiahow'), 2043), (('work', 'australiahow', 'many'), 1988), (('australiahow', 'many', 'years'), 1986), (('expected', 'annual', 'base'), 958), (('right', 'work', 'australia'), 901)]\n",
      "\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "class NLP_ngrams():\n",
    "    def merge_documents_into_list(self, df, colname):\n",
    "        # store all column values into a list of strings\n",
    "        lst = []\n",
    "        for row in df[colname]:\n",
    "            if not isinstance(row, str): continue\n",
    "            lst += word_tokenize(row)\n",
    "        return lst\n",
    "    \n",
    "    def get_column_n_most_frequent_unigrams(self, df, colname, n):\n",
    "        lst = self.merge_documents_into_list(df, colname)\n",
    "        counts = {}\n",
    "        for word in lst: counts[word] = counts.get(word, 0) + 1\n",
    "        # return list of tuples (unigram, frequency) sorted by the frequency in decreasing order\n",
    "        return sorted(counts.items(), key=lambda x:x[1], reverse=True)[:n]\n",
    "        \n",
    "    def get_column_n_most_frequent_bigrams(self, df, colname, n, freq_filter=10):\n",
    "        lst = self.merge_documents_into_list(df, colname)\n",
    "        bcf = BigramCollocationFinder.from_words(lst)\n",
    "        bcf.apply_freq_filter(freq_filter) # filter bigrams that won't repeat at least 10 times\n",
    "        # return list of tuples (bigram, frequency) sorted by the frequency in decreasing order\n",
    "        return sorted(list(bcf.ngram_fd.items()), key=lambda x:x[1], reverse=True)[:n]\n",
    "    \n",
    "    def get_column_n_most_frequent_trigrams(self, df, colname, n, freq_filter=10):\n",
    "        lst = self.merge_documents_into_list(df, colname)\n",
    "        tcf = TrigramCollocationFinder.from_words(lst)\n",
    "        tcf.apply_freq_filter(freq_filter) # filter trigrams that won't repeat at least 10 times\n",
    "        # return list of tuples (trigram, frequency) sorted by the frequency in decreasing order\n",
    "        return sorted(list(tcf.ngram_fd.items()), key=lambda x:x[1], reverse=True)[:n]\n",
    "\n",
    "    def get_top_x_most_frequent_ngrams_of_column(self, df, colname, x):\n",
    "        # get the most frequent n-grams (uni, bi, and tri) within the column values\n",
    "        top_x_unigrams = self.get_column_n_most_frequent_unigrams(df, colname, x)\n",
    "        top_x_bigrams = self.get_column_n_most_frequent_bigrams(df, colname, x)\n",
    "        top_x_trigrams = self.get_column_n_most_frequent_trigrams(df, colname, x)\n",
    "        top_x_ngrams = [top_x_unigrams, top_x_bigrams, top_x_trigrams]\n",
    "        return top_x_ngrams\n",
    "    \n",
    "def get_top_x_most_frequent_ngrams_of_columns(df, colnames, x_cols):\n",
    "    ngram_names = {1:'unigrams', 2:'bigrams', 3:'trigrams'}\n",
    "    nlp = NLP_ngrams()\n",
    "    ngrams = {}\n",
    "    # loop through column names, display only top 10 most frequent n-grams, but save the top x ngrams passed as parameters\n",
    "    for i in range(len(colnames)):\n",
    "        # save top x most frequent ngrams of the column\n",
    "        column_ngrams = nlp.get_top_x_most_frequent_ngrams_of_column(df, colnames[i], x_cols[i])\n",
    "        \n",
    "        # save it in a dictionary (key = column name, value = list of lists of ngrams)\n",
    "        ngrams[colnames[i]] = column_ngrams\n",
    "        \n",
    "        # display only top 10 ngrams for each column\n",
    "        for j in range(1,4):\n",
    "            print(\"Top 10\", ngram_names[j], \"of column '\"+colnames[i]+\"':\")\n",
    "            print(column_ngrams[j-1][:10], end=\"\\n\\n\")\n",
    "        print(\"-\"*35)\n",
    "    \n",
    "    return ngrams # return the dictionary (keys = column names, values = list of ngrams)\n",
    "        \n",
    "colnames = ['title', 'location', 'department', 'description', 'company_questions']\n",
    "xs = [200 for _ in range(len(text_cols))] # we will get top 200 of every column\n",
    "ngrams_per_column = get_top_x_most_frequent_ngrams_of_columns(df, colnames, xs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ebb2cef4-caca-4847-8615-44701082cfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7f8767f-bf95-45bb-888e-47e3f5ee62e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5398"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09d3ab-664d-47f1-85bf-2a67ae53bd37",
   "metadata": {},
   "source": [
    "We have seen some of the most frequent n-grams (unigrams, bigrams, and trigrams) for all our text columns.\n",
    "\n",
    "Let's __replace the each column values with the most common n-grams found for each column__.\n",
    "\n",
    "This will serve us as a method to standardize values and reduce the number of categorical unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2fe59c7-c4ad-475d-84ae-f7dd27bd3212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NLP_replace_values():\n",
    "    def replace_column_values_based_on_ngrams(self, df, colname, ngrams):\n",
    "        # save all ngrams into a list for search purposes\n",
    "        list_unigrams = [[tuple_[0]] for tuple_ in ngrams[0]] \n",
    "        list_bigrams = [list(tuple_[0])  for tuple_ in ngrams[1]]\n",
    "        list_trigrams = [list(tuple_[0])  for tuple_ in ngrams[2]]\n",
    "        list_ngrams = [list_unigrams, list_bigrams, list_trigrams]\n",
    "            \n",
    "        # loop through column rows and replace the value with most common ngram\n",
    "        for i, value in enumerate(df[colname]):\n",
    "            # tokenize row value\n",
    "            tokens = word_tokenize(value)\n",
    "            \n",
    "            # save most frequen ngram, and its frequency for comparing purposes\n",
    "            highest_ngram, highest_ngram_frequency = \"\", -1\n",
    "            \n",
    "            # loop through ngrams (start by looking for trigrams within the tokenized words, if not found, search for bigrams, finally unigrams)\n",
    "            for j in range(2,-1,-1):\n",
    "                # list of unigrams, bigrams, or trigrams depending on iteration\n",
    "                j_ngrams = list_ngrams[j]\n",
    "                \n",
    "                # loop through tokenized words\n",
    "                for k in range(len(tokens) - j):\n",
    "                    # set current ngram, if ngram not found on the top most frequent, skip iteration\n",
    "                    ngram = tokens[k : k + j + 1]\n",
    "                    if ngram not in j_ngrams: continue\n",
    "                    \n",
    "                    # otherwise, if found, get the frequency of the ngram\n",
    "                    ngram_frequency = ngrams[j][j_ngrams.index(ngram)][1]\n",
    "                    \n",
    "                    # if the frequency is higher, replace values\n",
    "                    if ngram_frequency > highest_ngram_frequency:\n",
    "                        highest_ngram, highest_ngram_frequency = ngram, ngram_frequency\n",
    "                        \n",
    "                # if we found a trigram, we don't need to look for bigrams or unigrams\n",
    "                # if we found a bigram, we don't need to look for unigrams\n",
    "                if highest_ngram != \"\":\n",
    "                    break\n",
    "            \n",
    "            # finally replace the row value with the frequent ngram identified\n",
    "            df.iloc[i][colname] = ' '.join(highest_ngram)\n",
    "            \n",
    "nlp = NLP_replace_values()\n",
    "nlp.replace_column_values_based_on_ngrams(df2, 'title', ngrams_per_column['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20f4cfc4-3d8c-4caf-9802-155cdac32b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2425437-b021-49a1-b85b-6674bc1a9251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager                491\n",
      "officer                385\n",
      "                       301\n",
      "coordinator            272\n",
      "assistant              202\n",
      "                      ... \n",
      "territory                1\n",
      "manager property         1\n",
      "engineer mechanical      1\n",
      "housing                  1\n",
      "manager general          1\n",
      "Name: title, Length: 400, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2['title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44143edb-5f23-41b9-804f-fe754f48f328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support worker</td>\n",
       "      <td>Ability Gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>wagga wagga wagga wagga riverina</td>\n",
       "      <td>aged disability support community services dev...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>uswe outcome focused ndis service provider bas...</td>\n",
       "      <td>regular access carwhich following statements b...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regional manager</td>\n",
       "      <td>CatholicCare Tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>launceston launceston north east</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>catholiccare tasmania primary social services ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>support worker</td>\n",
       "      <td>Community Gro</td>\n",
       "      <td>$40 – $44 per hour</td>\n",
       "      <td>townsville northern</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>community gro inc communitybased nonprofit org...</td>\n",
       "      <td>following statements best describes right work...</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>https://www.seek.com.au/job/73832771?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case manager</td>\n",
       "      <td>Open Minds</td>\n",
       "      <td>$82k – 84k + super + salary packaging + benefits</td>\n",
       "      <td>nambour sunshine coast</td>\n",
       "      <td>community development community services devel...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>case manager coastal supports open minds sunsh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901240?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worker</td>\n",
       "      <td>The Centre for Women &amp; Co.</td>\n",
       "      <td>$41 – $42 per hour</td>\n",
       "      <td>underwood brisbane</td>\n",
       "      <td>child welfare youth family services community ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>team culture centre women men services work su...</td>\n",
       "      <td>following statements best describes right work...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73861002?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>support engineer</td>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sydney</td>\n",
       "      <td>help desk it support information communication...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>opportunityas part exciting growth expansion s...</td>\n",
       "      <td>following statements best describes right work...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73930150?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>team leader</td>\n",
       "      <td>Labourforce</td>\n",
       "      <td>$47 per hour + penalties</td>\n",
       "      <td>wetherill park sydney</td>\n",
       "      <td>warehousing storage distribution manufacturing...</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>client one australias leading manufacturer dis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73870879?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>casual retail assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>randwick sydney</td>\n",
       "      <td>retail assistants retail consumer products</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>independent living specialists fastgrowing bus...</td>\n",
       "      <td>customer service experiencedo current ndis wor...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>assistant</td>\n",
       "      <td>Cendre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oxenford gold coast</td>\n",
       "      <td>pickers packers manufacturing transport logistics</td>\n",
       "      <td>Full time</td>\n",
       "      <td>cendré revered ecommerce jewellery brand compr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73875587?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>it support officer</td>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northmead sydney</td>\n",
       "      <td>help desk it support information communication...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>parramatta locationwork closeknit experienced ...</td>\n",
       "      <td>demonstrated experience diagnosing repairing m...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73868216?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title                         company  \\\n",
       "0              support worker                 Ability Gateway   \n",
       "1            regional manager           CatholicCare Tasmania   \n",
       "2              support worker                   Community Gro   \n",
       "3                case manager                      Open Minds   \n",
       "4                      worker      The Centre for Women & Co.   \n",
       "...                       ...                             ...   \n",
       "9795         support engineer         Fuse Technology Pty Ltd   \n",
       "9796              team leader                     Labourforce   \n",
       "9797  casual retail assistant  Independent Living Specialists   \n",
       "9798                assistant                          Cendre   \n",
       "9799       it support officer                   Hare & Forbes   \n",
       "\n",
       "                                                salary  \\\n",
       "0                                $35.50 per hour [PPT]   \n",
       "1                                                  NaN   \n",
       "2                                   $40 – $44 per hour   \n",
       "3     $82k – 84k + super + salary packaging + benefits   \n",
       "4                                   $41 – $42 per hour   \n",
       "...                                                ...   \n",
       "9795                                               NaN   \n",
       "9796                          $47 per hour + penalties   \n",
       "9797                       $31.11 per hour, plus super   \n",
       "9798                                               NaN   \n",
       "9799                                               NaN   \n",
       "\n",
       "                              location  \\\n",
       "0     wagga wagga wagga wagga riverina   \n",
       "1     launceston launceston north east   \n",
       "2                  townsville northern   \n",
       "3               nambour sunshine coast   \n",
       "4                   underwood brisbane   \n",
       "...                                ...   \n",
       "9795                            sydney   \n",
       "9796             wetherill park sydney   \n",
       "9797                   randwick sydney   \n",
       "9798               oxenford gold coast   \n",
       "9799                  northmead sydney   \n",
       "\n",
       "                                             department             type  \\\n",
       "0     aged disability support community services dev...        Part time   \n",
       "1     child welfare youth family services community ...        Full time   \n",
       "2     child welfare youth family services community ...        Full time   \n",
       "3     community development community services devel...        Full time   \n",
       "4     child welfare youth family services community ...        Full time   \n",
       "...                                                 ...              ...   \n",
       "9795  help desk it support information communication...        Full time   \n",
       "9796  warehousing storage distribution manufacturing...    Contract/Temp   \n",
       "9797         retail assistants retail consumer products  Casual/Vacation   \n",
       "9798  pickers packers manufacturing transport logistics        Full time   \n",
       "9799  help desk it support information communication...        Full time   \n",
       "\n",
       "                                            description  \\\n",
       "0     uswe outcome focused ndis service provider bas...   \n",
       "1     catholiccare tasmania primary social services ...   \n",
       "2     community gro inc communitybased nonprofit org...   \n",
       "3     case manager coastal supports open minds sunsh...   \n",
       "4     team culture centre women men services work su...   \n",
       "...                                                 ...   \n",
       "9795  opportunityas part exciting growth expansion s...   \n",
       "9796  client one australias leading manufacturer dis...   \n",
       "9797  independent living specialists fastgrowing bus...   \n",
       "9798  cendré revered ecommerce jewellery brand compr...   \n",
       "9799  parramatta locationwork closeknit experienced ...   \n",
       "\n",
       "                                      company_questions posted_date  \\\n",
       "0     regular access carwhich following statements b...  2024-02-21   \n",
       "1                                                   NaN  2024-02-21   \n",
       "2     following statements best describes right work...  2024-02-19   \n",
       "3                                                   NaN  2024-02-21   \n",
       "4     following statements best describes right work...  2024-02-20   \n",
       "...                                                 ...         ...   \n",
       "9795  following statements best describes right work...  2024-02-21   \n",
       "9796                                                NaN  2024-02-21   \n",
       "9797  customer service experiencedo current ndis wor...  2024-02-21   \n",
       "9798                                                NaN  2024-02-21   \n",
       "9799  demonstrated experience diagnosing repairing m...  2024-02-21   \n",
       "\n",
       "                                                   link  \n",
       "0     https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1     https://www.seek.com.au/job/73909232?type=prom...  \n",
       "2     https://www.seek.com.au/job/73832771?type=stan...  \n",
       "3     https://www.seek.com.au/job/73901240?type=stan...  \n",
       "4     https://www.seek.com.au/job/73861002?type=stan...  \n",
       "...                                                 ...  \n",
       "9795  https://www.seek.com.au/job/73930150?type=stan...  \n",
       "9796  https://www.seek.com.au/job/73870879?type=stan...  \n",
       "9797  https://www.seek.com.au/job/73899163?type=stan...  \n",
       "9798  https://www.seek.com.au/job/73875587?type=stan...  \n",
       "9799  https://www.seek.com.au/job/73868216?type=stan...  \n",
       "\n",
       "[9800 rows x 10 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
