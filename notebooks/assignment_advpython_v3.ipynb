{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd48a22-2567-4638-9d23-c507eb6db083",
   "metadata": {},
   "source": [
    "### Advanced Python AI and ML Tools - Assignment 1\n",
    "\n",
    "__Group Members:__\n",
    "1) Aanal Patel - C0910376\n",
    "2) Bimal Shresta - C0919385\n",
    "3) Danilo Diaz - C0889539\n",
    "4) Ernie Sumoso - C0881591"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d8930-578d-4157-b1c5-368a73ef4b63",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index\n",
    "- __Step 1. Dataset Description (web scrapped)__\n",
    "- __Step 2. Data Wrangling (cleaning, formatting, structuring, validating)__\n",
    "    - __Step 9. NLP techniques: data cleaning, stopword and puctuation removal, tokenizing, ngrams analysis__\n",
    "- __Step 3. Plotting methods for distribution__\n",
    "- __Step 4. Pandas profiling for EDA (exploratory data analysis)__\n",
    "- __Step 5. Encoding methods, creating new numerical columns__\n",
    "- __Step 6. Outlier identification (with boxplots and IQR)__\n",
    "- __Step 7. Addressing outliers with Quantile-based flooring and capping, Trimming, and Log Transformation__\n",
    "- __Step 8. Unsupervised learning methods__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3e558-267b-4d55-8b33-4c33c6e77d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1. Dataset Description (web scrapped)\n",
    "\n",
    "(Bimal add a description of what you did to web scrap the data here, what is the source and what were your steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a9a780-fd82-442c-bce2-85cd9bc8e1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>job_location</th>\n",
       "      <th>post</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_desc</th>\n",
       "      <th>company_qns</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The opportunityAs part of our exciting growth ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73930150?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>Labourforce</td>\n",
       "      <td>$47 per hour + penalties</td>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Our client is one of Australia's leading Manuf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73870879?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>Cendre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Cendré is a revered e-commerce jewellery brand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73875587?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Parramatta locationWork with a close-knit, exp...</td>\n",
       "      <td>Do you have demonstrated experience diagnosing...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73868216?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_title  \\\n",
       "2610                         Level 2/3 Support Engineer   \n",
       "2611  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "2612                            Casual Retail Assistant   \n",
       "2613                                   Studio Assistant   \n",
       "2614                          Junior IT Support Officer   \n",
       "\n",
       "                             company                       salary  \\\n",
       "2610         Fuse Technology Pty Ltd                          NaN   \n",
       "2611                     Labourforce     $47 per hour + penalties   \n",
       "2612  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "2613                          Cendre                          NaN   \n",
       "2614                   Hare & Forbes                          NaN   \n",
       "\n",
       "                    job_location  \\\n",
       "2610                  Sydney NSW   \n",
       "2611  Wetherill Park, Sydney NSW   \n",
       "2612        Randwick, Sydney NSW   \n",
       "2613    Oxenford, Gold Coast QLD   \n",
       "2614       Northmead, Sydney NSW   \n",
       "\n",
       "                                                   post         job_type  \\\n",
       "2610  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "2611  Warehousing, Storage & Distribution (Manufactu...    Contract/Temp   \n",
       "2612     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "2613  Pickers & Packers (Manufacturing, Transport & ...        Full time   \n",
       "2614  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "\n",
       "                                               job_desc  \\\n",
       "2610  The opportunityAs part of our exciting growth ...   \n",
       "2611  Our client is one of Australia's leading Manuf...   \n",
       "2612  Independent Living Specialists is a fast-growi...   \n",
       "2613  Cendré is a revered e-commerce jewellery brand...   \n",
       "2614  Parramatta locationWork with a close-knit, exp...   \n",
       "\n",
       "                                            company_qns job_posted_date  \\\n",
       "2610  Which of the following statements best describ...      2024-02-21   \n",
       "2611                                                NaN      2024-02-21   \n",
       "2612  Do you have customer service experience?Do you...      2024-02-21   \n",
       "2613                                                NaN      2024-02-21   \n",
       "2614  Do you have demonstrated experience diagnosing...      2024-02-21   \n",
       "\n",
       "                                               job_link  \n",
       "2610  https://www.seek.com.au/job/73930150?type=stan...  \n",
       "2611  https://www.seek.com.au/job/73870879?type=stan...  \n",
       "2612  https://www.seek.com.au/job/73899163?type=stan...  \n",
       "2613  https://www.seek.com.au/job/73875587?type=stan...  \n",
       "2614  https://www.seek.com.au/job/73868216?type=stan...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading the web scrapped data from CSV file, setting the index column\n",
    "df = pd.read_csv(\"job_data.csv\", index_col=0)\n",
    "\n",
    "# displaying the raw data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d79c30-ba28-4b8b-a6ee-425ac8107091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 9800\n",
      "Number of Columns: 10\n",
      "Index(['job_title', 'company', 'salary', 'job_location', 'post', 'job_type',\n",
      "       'job_desc', 'company_qns', 'job_posted_date', 'job_link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# display the number of rows, columns and the column names\n",
    "def display_shape_and_colnames(df):\n",
    "    print(\"Number of Rows:\", df.shape[0])\n",
    "    print(\"Number of Columns:\", df.shape[1])\n",
    "    print(df.columns)\n",
    "    \n",
    "display_shape_and_colnames(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837f9d0-3dc3-4986-a9df-337ddc17e9b7",
   "metadata": {},
   "source": [
    "Some of our __column names__ are __redundant__ because we are working with job data.\n",
    "\n",
    "Let's delete the prefix __\"job\"__ from our column names.\n",
    "\n",
    "Some other __column names__ are __abbreviated__ (e.g. \"job_desc\", \"company_qns\").\n",
    "\n",
    "Let's __replace them with full names__ so we can have accurate column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8e2f7a-9d56-4e39-8b51-b145d797646c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experienced Support Worker (PPT &amp; CAS)</td>\n",
       "      <td>Ability Gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>Wagga Wagga, Wagga Wagga &amp; Riverina NSW</td>\n",
       "      <td>Aged &amp; Disability Support (Community Services ...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regional Manager - Inspire@HOME</td>\n",
       "      <td>CatholicCare Tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Launceston, Launceston &amp; North East TAS</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title                company  \\\n",
       "0  Experienced Support Worker (PPT & CAS)        Ability Gateway   \n",
       "1         Regional Manager - Inspire@HOME  CatholicCare Tasmania   \n",
       "\n",
       "                  salary                                 location  \\\n",
       "0  $35.50 per hour [PPT]  Wagga Wagga, Wagga Wagga & Riverina NSW   \n",
       "1                    NaN  Launceston, Launceston & North East TAS   \n",
       "\n",
       "                                          department       type  \\\n",
       "0  Aged & Disability Support (Community Services ...  Part time   \n",
       "1  Child Welfare, Youth & Family Services (Commun...  Full time   \n",
       "\n",
       "                                         description  \\\n",
       "0  About usWe are an outcome focused NDIS service...   \n",
       "1  CatholicCare Tasmania is the primary social se...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  Do you own or have regular access to a car?Whi...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_colnames(df):\n",
    "    # delete the prefix \"job_\" on our column names\n",
    "    for column_name in df.columns.to_list():\n",
    "        if column_name.startswith(\"job_\"):\n",
    "            df.rename(columns={column_name : column_name.lstrip(\"job_\")}, inplace=True)\n",
    "\n",
    "    # rename abbreviated column names\n",
    "    df.rename(columns={'desc':'description', 'company_qns':'company_questions', 'post':'department'}, inplace=True)\n",
    "\n",
    "clean_colnames(df)\n",
    "# display clean column names\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7c020-0c61-4025-8b53-9283211d7ff5",
   "metadata": {},
   "source": [
    "Now let's undestand all of our columns by providing a description to each one:\n",
    "- __title__: title of the posted job\n",
    "- __company__: name of the company that has posted the job\n",
    "- __salary__: salary range for the job, can be defined per hour, monthly, annually, etc.\n",
    "- __location__: geographical location of the job or company\n",
    "- __department__: field or department of the job (e.g. IT, Sales, etc.)\n",
    "- __description__: long description of the job posting\n",
    "- __company_questions__: questions issued by the company to the applicants, according to the post\n",
    "- __posted_date__: format yyyy-mm-dd\n",
    "- __link__: link of the job posting\n",
    "\n",
    "Now that we have a general understanding of our web scrapped data. \n",
    "\n",
    "Let's go ahead to the next step to perform our data wrangling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7c8b0-5e4d-44bc-9c1f-253acadabe00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Step 2.__ Data Wrangling (cleaning, formatting, structuring, validating)\n",
    "### (includes __Step 9.__ NLP techniques: data cleaning, stopword and puctuation removal, tokenizing, ngrams analysis)\n",
    "\n",
    "First of all, we have 9800 rows, however the index values are repetead thrice because of the CSV contents.\n",
    "\n",
    "Let's start by reseting the index to have proper index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ba62e5-9313-4bb3-aa44-92bc5f8ca10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The opportunityAs part of our exciting growth ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73930150?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>Labourforce</td>\n",
       "      <td>$47 per hour + penalties</td>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Our client is one of Australia's leading Manuf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73870879?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>Cendre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Cendré is a revered e-commerce jewellery brand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73875587?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>Help Desk &amp; IT Support (Information &amp; Communic...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Parramatta locationWork with a close-knit, exp...</td>\n",
       "      <td>Do you have demonstrated experience diagnosing...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73868216?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "9795                         Level 2/3 Support Engineer   \n",
       "9796  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "9797                            Casual Retail Assistant   \n",
       "9798                                   Studio Assistant   \n",
       "9799                          Junior IT Support Officer   \n",
       "\n",
       "                             company                       salary  \\\n",
       "9795         Fuse Technology Pty Ltd                          NaN   \n",
       "9796                     Labourforce     $47 per hour + penalties   \n",
       "9797  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "9798                          Cendre                          NaN   \n",
       "9799                   Hare & Forbes                          NaN   \n",
       "\n",
       "                        location  \\\n",
       "9795                  Sydney NSW   \n",
       "9796  Wetherill Park, Sydney NSW   \n",
       "9797        Randwick, Sydney NSW   \n",
       "9798    Oxenford, Gold Coast QLD   \n",
       "9799       Northmead, Sydney NSW   \n",
       "\n",
       "                                             department             type  \\\n",
       "9795  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "9796  Warehousing, Storage & Distribution (Manufactu...    Contract/Temp   \n",
       "9797     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "9798  Pickers & Packers (Manufacturing, Transport & ...        Full time   \n",
       "9799  Help Desk & IT Support (Information & Communic...        Full time   \n",
       "\n",
       "                                            description  \\\n",
       "9795  The opportunityAs part of our exciting growth ...   \n",
       "9796  Our client is one of Australia's leading Manuf...   \n",
       "9797  Independent Living Specialists is a fast-growi...   \n",
       "9798  Cendré is a revered e-commerce jewellery brand...   \n",
       "9799  Parramatta locationWork with a close-knit, exp...   \n",
       "\n",
       "                                      company_questions posted_date  \\\n",
       "9795  Which of the following statements best describ...  2024-02-21   \n",
       "9796                                                NaN  2024-02-21   \n",
       "9797  Do you have customer service experience?Do you...  2024-02-21   \n",
       "9798                                                NaN  2024-02-21   \n",
       "9799  Do you have demonstrated experience diagnosing...  2024-02-21   \n",
       "\n",
       "                                                   link  \n",
       "9795  https://www.seek.com.au/job/73930150?type=stan...  \n",
       "9796  https://www.seek.com.au/job/73870879?type=stan...  \n",
       "9797  https://www.seek.com.au/job/73899163?type=stan...  \n",
       "9798  https://www.seek.com.au/job/73875587?type=stan...  \n",
       "9799  https://www.seek.com.au/job/73868216?type=stan...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the rows index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e276f656-3fad-4023-a673-e95481b2d89c",
   "metadata": {},
   "source": [
    "Now, let's perform some basic analysis on our dataset.\n",
    "\n",
    "We will check the following stats by implementing functions:\n",
    "- missing values per column\n",
    "- duplicated rows\n",
    "- number of unique values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d8490f-0b52-4dea-ac76-d5fd4e4b5dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Missing Values\n",
      "title                   0\n",
      "company                 0\n",
      "salary               5216\n",
      "location                0\n",
      "department              0\n",
      "type                    0\n",
      "description             0\n",
      "company_questions    5034\n",
      "posted_date             0\n",
      "link                    0\n",
      "dtype: int64\n",
      "\n",
      "% Missing Values\n",
      "title                 0.000000\n",
      "company               0.000000\n",
      "salary               53.224490\n",
      "location              0.000000\n",
      "department            0.000000\n",
      "type                  0.000000\n",
      "description           0.000000\n",
      "company_questions    51.367347\n",
      "posted_date           0.000000\n",
      "link                  0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    # check for number of missing values per column\n",
    "    print(\"# Missing Values\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # check for % of missing values\n",
    "    print(\"\\n% Missing Values\")\n",
    "    print(df.isna().mean() * 100)\n",
    "    \n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511b597-6839-49ed-9fcb-852fce895035",
   "metadata": {},
   "source": [
    "As expected, many job posts do not include a salary range or any information about the salary.\n",
    "\n",
    "It is no surprise that __more than half of our data has missing values for salary__.\n",
    "\n",
    "We also have __more than half missing values for the company questions column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c435ba31-552a-4e09-898d-80df73894ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Duplicated Values\n",
      "944\n",
      "\n",
      "% Duplicated Values\n",
      "9.63265306122449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>Pick Packers</td>\n",
       "      <td>Action Workforce</td>\n",
       "      <td>35</td>\n",
       "      <td>Maddington, Perth WA</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution (Manufactu...</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Action Workforce are looking for Experienced P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901168?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>Accounts Person- KALGOORLIE RESIDENTS ONLY</td>\n",
       "      <td>Golden mile cleaning services</td>\n",
       "      <td>$30 – $33.50 per hour</td>\n",
       "      <td>Kalgoorlie, Kalgoorlie, Goldfields &amp; Esperance WA</td>\n",
       "      <td>Administrative Assistants (Administration &amp; Of...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>Job Title: Accounts Person We are currently se...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73908087?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9788</th>\n",
       "      <td>Warehouse Assistant</td>\n",
       "      <td>Omni Recruit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truganina, Melbourne VIC</td>\n",
       "      <td>Pickers &amp; Packers (Manufacturing, Transport &amp; ...</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Business is booming and we are currently seeki...</td>\n",
       "      <td>Do you agree to the privacy policy of Omni Rec...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73863322?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>$31.11 per hour, plus super</td>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>Retail Assistants (Retail &amp; Consumer Products)</td>\n",
       "      <td>Casual/Vacation</td>\n",
       "      <td>Independent Living Specialists is a fast-growi...</td>\n",
       "      <td>Do you have customer service experience?Do you...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73899163?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "9772                                Pick Packers   \n",
       "9778  Accounts Person- KALGOORLIE RESIDENTS ONLY   \n",
       "9788                         Warehouse Assistant   \n",
       "9797                     Casual Retail Assistant   \n",
       "\n",
       "                             company                       salary  \\\n",
       "9772                Action Workforce                           35   \n",
       "9778   Golden mile cleaning services        $30 – $33.50 per hour   \n",
       "9788                    Omni Recruit                          NaN   \n",
       "9797  Independent Living Specialists  $31.11 per hour, plus super   \n",
       "\n",
       "                                               location  \\\n",
       "9772                               Maddington, Perth WA   \n",
       "9778  Kalgoorlie, Kalgoorlie, Goldfields & Esperance WA   \n",
       "9788                           Truganina, Melbourne VIC   \n",
       "9797                               Randwick, Sydney NSW   \n",
       "\n",
       "                                             department             type  \\\n",
       "9772  Warehousing, Storage & Distribution (Manufactu...  Casual/Vacation   \n",
       "9778  Administrative Assistants (Administration & Of...        Part time   \n",
       "9788  Pickers & Packers (Manufacturing, Transport & ...  Casual/Vacation   \n",
       "9797     Retail Assistants (Retail & Consumer Products)  Casual/Vacation   \n",
       "\n",
       "                                            description  \\\n",
       "9772  Action Workforce are looking for Experienced P...   \n",
       "9778  Job Title: Accounts Person We are currently se...   \n",
       "9788  Business is booming and we are currently seeki...   \n",
       "9797  Independent Living Specialists is a fast-growi...   \n",
       "\n",
       "                                      company_questions posted_date  \\\n",
       "9772                                                NaN  2024-02-21   \n",
       "9778  Which of the following statements best describ...  2024-02-21   \n",
       "9788  Do you agree to the privacy policy of Omni Rec...  2024-02-20   \n",
       "9797  Do you have customer service experience?Do you...  2024-02-21   \n",
       "\n",
       "                                                   link  \n",
       "9772  https://www.seek.com.au/job/73901168?type=stan...  \n",
       "9778  https://www.seek.com.au/job/73908087?type=prom...  \n",
       "9788  https://www.seek.com.au/job/73863322?type=stan...  \n",
       "9797  https://www.seek.com.au/job/73899163?type=stan...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_duplicated_values(df):\n",
    "    # check for number of duplicated values\n",
    "    print(\"# Duplicated Values\")\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    # check for % of duplicated values\n",
    "    print(\"\\n% Duplicated Values\")\n",
    "    print(df.duplicated().mean() * 100)\n",
    "\n",
    "check_duplicated_values(df)\n",
    "\n",
    "df[df.duplicated()].tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141d4cf-c61e-4847-bc3f-49c84247f2d6",
   "metadata": {},
   "source": [
    "Some considerable amount of our data __(around 9.5%) are duplicated__ rows.\n",
    "\n",
    "This can be __dangerous for analysis__, we have to __deal with these duplicated values__ in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f48a36-28e8-4ff6-8df1-57c0f9c822f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Values per Column\n",
      "'title' # of unique values: 5655\n",
      "'company' # of unique values: 4965\n",
      "'salary' # of unique values: 2645\n",
      "'location' # of unique values: 1448\n",
      "'department' # of unique values: 451\n",
      "'type' # of unique values: 8\n",
      "'description' # of unique values: 7958\n",
      "'company_questions' # of unique values: 2730\n",
      "'posted_date' # of unique values: 95\n",
      "'link' # of unique values: 8664\n",
      "\n",
      "% Unique Values per Column\n",
      "'title' % of unique values: 57.7 %\n",
      "'company' % of unique values: 50.66 %\n",
      "'salary' % of unique values: 26.99 %\n",
      "'location' % of unique values: 14.78 %\n",
      "'department' % of unique values: 4.6 %\n",
      "'type' % of unique values: 0.08 %\n",
      "'description' % of unique values: 81.2 %\n",
      "'company_questions' % of unique values: 27.86 %\n",
      "'posted_date' % of unique values: 0.97 %\n",
      "'link' % of unique values: 88.41 %\n"
     ]
    }
   ],
   "source": [
    "def check_nunique_values(df):\n",
    "    # check number of unique values per column\n",
    "    print(\"# Unique Values per Column\")\n",
    "    for col in df.columns:\n",
    "        print(\"'\"+col+\"'\", \"# of unique values:\", df[col].nunique())\n",
    "        \n",
    "    # check % of unique values per column (relative to number of total rows in the dataset)\n",
    "    print(\"\\n% Unique Values per Column\")\n",
    "    for col in df.columns:\n",
    "        print(\"'\"+col+\"'\", \"% of unique values:\", round(df[col].nunique() * 100 / df.shape[0], 2), \"%\")\n",
    "        \n",
    "check_nunique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e88d6-fc2a-4f32-aa18-43a753474b66",
   "metadata": {},
   "source": [
    "Some of our columns have a __large amount of unique values__.\n",
    "\n",
    "The with vast amount of unique values __(>50% of total rows)__.\n",
    "- title\n",
    "- company\n",
    "- description\n",
    "- link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3423f09-458a-47af-a4e3-e1ddb1371a51",
   "metadata": {},
   "source": [
    "We will start with some basic cleaning applying some NLP methods that includes:\n",
    "- removing punctuation\n",
    "- removing digits\n",
    "- apply lower case to all letters\n",
    "- removing extra whitespaces\n",
    "\n",
    "We will start dealing with the following columns:\n",
    "- title\n",
    "- company\n",
    "- location\n",
    "\n",
    "For this, we will implement classes that __contain NLP methods/techniques__, this code can be re-used later for other columns like 'description', etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b61c0e-6e6e-44a3-be52-9ddcefbd6691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "# class containing our implemented NLP techniques and methods\n",
    "class NLP():\n",
    "    \n",
    "    # remove all punctuation from a word (string)\n",
    "    def remove_punctuation(self, word):\n",
    "        if not isinstance(word, str): return word\n",
    "        return word.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # remove all digits/numbers from a word (string)\n",
    "    def remove_digits(self, word):\n",
    "        if not isinstance(word, str): return word\n",
    "        return re.sub(r'\\d+', '', word)\n",
    "    \n",
    "    # checks if word is a string and returns lower cased\n",
    "    def lower_word(self, word):\n",
    "        if not isinstance(word, str): return word\n",
    "        return word.lower()\n",
    "\n",
    "    # perform basic operations to clean 1 column of a dataframe\n",
    "    def basic_clean_text_column(self, df, colname):\n",
    "        print(\"Basic cleaning on column '\" + colname + \"':\")\n",
    "        nunique = df[colname].nunique()\n",
    "        print(\"# Unique values before cleaning:\", df[colname].nunique())\n",
    "        for value in df[colname].unique():\n",
    "            # save original value to replace later\n",
    "            og_value = value\n",
    "            \n",
    "            # if we are dealing with a null value, don't modify anything\n",
    "            if value is np.nan: continue\n",
    "            \n",
    "            # remove punctuation from the column value\n",
    "            value = self.remove_punctuation(str(value))\n",
    "            \n",
    "            # remove digits from column value\n",
    "            value = self.remove_digits(value)\n",
    "            \n",
    "            # lower case column value\n",
    "            value = self.lower_word(value)\n",
    "            \n",
    "            # word tokenize the column value\n",
    "            word_tokens = word_tokenize(value)\n",
    "            \n",
    "            # update df value in place\n",
    "            df[colname].replace(og_value, ' '.join(word_tokens), inplace=True)\n",
    "        new_nunique = df[colname].nunique()\n",
    "        print(\"# Unique values after cleaning:\", df[colname].nunique())\n",
    "        print(\"% of unique values reduction:\", round(100 - (new_nunique*100/nunique),2), \"%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6c780-abb2-4a8d-b79a-3a64c2f89fdf",
   "metadata": {},
   "source": [
    "Now that we have implemented a class for our methods,\n",
    "\n",
    "let's go ahead and __apply a basic cleaning on all our columns__.\n",
    "\n",
    "Then, we can __compare values before vs after cleaning__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73deb158-a819-4850-8576-6ddbcc24a1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'title':\n",
      "# Unique values before cleaning: 5655\n",
      "# Unique values after cleaning: 5541\n",
      "% of unique values reduction: 2.02 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>clean title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experienced Support Worker (PPT &amp; CAS)</td>\n",
       "      <td>experienced support worker ppt cas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regional Manager - Inspire@HOME</td>\n",
       "      <td>regional manager inspirehome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family Support Worker</td>\n",
       "      <td>family support worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPS Case Manager</td>\n",
       "      <td>cps case manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intake Worker</td>\n",
       "      <td>intake worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Level 2/3 Support Engineer</td>\n",
       "      <td>level support engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...</td>\n",
       "      <td>night shift warehouse team leader wanted wethe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Casual Retail Assistant</td>\n",
       "      <td>casual retail assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Studio Assistant</td>\n",
       "      <td>studio assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Junior IT Support Officer</td>\n",
       "      <td>junior it support officer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                Experienced Support Worker (PPT & CAS)   \n",
       "1                       Regional Manager - Inspire@HOME   \n",
       "2                                 Family Support Worker   \n",
       "3                                      CPS Case Manager   \n",
       "4                                         Intake Worker   \n",
       "...                                                 ...   \n",
       "9795                         Level 2/3 Support Engineer   \n",
       "9796  NIGHT SHIFT WAREHOUSE TEAM LEADER WANTED WETHE...   \n",
       "9797                            Casual Retail Assistant   \n",
       "9798                                   Studio Assistant   \n",
       "9799                          Junior IT Support Officer   \n",
       "\n",
       "                                            clean title  \n",
       "0                    experienced support worker ppt cas  \n",
       "1                          regional manager inspirehome  \n",
       "2                                 family support worker  \n",
       "3                                      cps case manager  \n",
       "4                                         intake worker  \n",
       "...                                                 ...  \n",
       "9795                             level support engineer  \n",
       "9796  night shift warehouse team leader wanted wethe...  \n",
       "9797                            casual retail assistant  \n",
       "9798                                   studio assistant  \n",
       "9799                          junior it support officer  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_and_compare_column(df, colname):\n",
    "    # save raw title data into a new dataframe just to compare before vs after cleaning\n",
    "    df_compare = df[[colname]].copy()\n",
    "\n",
    "    # perform the basic cleaning on the title column\n",
    "    nlp = NLP()\n",
    "    nlp.basic_clean_text_column(df, colname)\n",
    "\n",
    "    # compare before vs after\n",
    "    df_compare[\"clean \"+colname] = df[colname]\n",
    "    display(df_compare)\n",
    "\n",
    "clean_and_compare_column(df, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56efc01-a23d-4b50-ae8a-bc3979da51b6",
   "metadata": {},
   "source": [
    "After this __1st experiment__ of __cleaning the 'title' column__ we notice that we have __reduced the number of unique values by 114__.\n",
    "\n",
    "Which is equivalent of aproximately __2% of the total unique values__, __not a significant reduction__.\n",
    "\n",
    "However, we have considerably clean our raw texts, and this will allow us to apply further NLP techniques that will have better results.\n",
    "\n",
    "Let's also __apply the same basic cleaning on the other 2 columns:__\n",
    "- company\n",
    "- location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76605134-4666-4978-9972-8697ac556f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'company':\n",
      "# Unique values before cleaning: 4965\n",
      "# Unique values after cleaning: 4965\n",
      "% of unique values reduction: 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>clean company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ability Gateway</td>\n",
       "      <td>ability gateway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatholicCare Tasmania</td>\n",
       "      <td>catholiccare tasmania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Community Gro</td>\n",
       "      <td>community gro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Open Minds</td>\n",
       "      <td>open minds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Centre for Women &amp; Co.</td>\n",
       "      <td>the centre for women co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Fuse Technology Pty Ltd</td>\n",
       "      <td>fuse technology pty ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>Labourforce</td>\n",
       "      <td>labourforce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Independent Living Specialists</td>\n",
       "      <td>independent living specialists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Cendre</td>\n",
       "      <td>cendre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Hare &amp; Forbes</td>\n",
       "      <td>hare forbes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company                   clean company\n",
       "0                    Ability Gateway                 ability gateway\n",
       "1              CatholicCare Tasmania           catholiccare tasmania\n",
       "2                      Community Gro                   community gro\n",
       "3                         Open Minds                      open minds\n",
       "4         The Centre for Women & Co.         the centre for women co\n",
       "...                              ...                             ...\n",
       "9795         Fuse Technology Pty Ltd         fuse technology pty ltd\n",
       "9796                     Labourforce                     labourforce\n",
       "9797  Independent Living Specialists  independent living specialists\n",
       "9798                          Cendre                          cendre\n",
       "9799                   Hare & Forbes                     hare forbes\n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic cleaning on column 'location':\n",
      "# Unique values before cleaning: 1448\n",
      "# Unique values after cleaning: 1448\n",
      "% of unique values reduction: 0.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>clean location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wagga Wagga, Wagga Wagga &amp; Riverina NSW</td>\n",
       "      <td>wagga wagga wagga wagga riverina nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Launceston, Launceston &amp; North East TAS</td>\n",
       "      <td>launceston launceston north east tas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Townsville, Northern QLD</td>\n",
       "      <td>townsville northern qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nambour, Sunshine Coast QLD</td>\n",
       "      <td>nambour sunshine coast qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Underwood, Brisbane QLD</td>\n",
       "      <td>underwood brisbane qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>sydney nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>Wetherill Park, Sydney NSW</td>\n",
       "      <td>wetherill park sydney nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>Randwick, Sydney NSW</td>\n",
       "      <td>randwick sydney nsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>Oxenford, Gold Coast QLD</td>\n",
       "      <td>oxenford gold coast qld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>Northmead, Sydney NSW</td>\n",
       "      <td>northmead sydney nsw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     location  \\\n",
       "0     Wagga Wagga, Wagga Wagga & Riverina NSW   \n",
       "1     Launceston, Launceston & North East TAS   \n",
       "2                    Townsville, Northern QLD   \n",
       "3                 Nambour, Sunshine Coast QLD   \n",
       "4                     Underwood, Brisbane QLD   \n",
       "...                                       ...   \n",
       "9795                               Sydney NSW   \n",
       "9796               Wetherill Park, Sydney NSW   \n",
       "9797                     Randwick, Sydney NSW   \n",
       "9798                 Oxenford, Gold Coast QLD   \n",
       "9799                    Northmead, Sydney NSW   \n",
       "\n",
       "                            clean location  \n",
       "0     wagga wagga wagga wagga riverina nsw  \n",
       "1     launceston launceston north east tas  \n",
       "2                  townsville northern qld  \n",
       "3               nambour sunshine coast qld  \n",
       "4                   underwood brisbane qld  \n",
       "...                                    ...  \n",
       "9795                            sydney nsw  \n",
       "9796             wetherill park sydney nsw  \n",
       "9797                   randwick sydney nsw  \n",
       "9798               oxenford gold coast qld  \n",
       "9799                  northmead sydney nsw  \n",
       "\n",
       "[9800 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the remaining text columns that we need to perform a basic clean\n",
    "text_cols = ['company', 'location']\n",
    "\n",
    "# implement a function to perform the cleaning on these columns\n",
    "def clean_and_compare_columns(df, cols):\n",
    "    for colname in cols:\n",
    "        clean_and_compare_column(df, colname)\n",
    "\n",
    "# call the implemented function\n",
    "clean_and_compare_columns(df, text_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a36db8-4d5f-45a3-8114-86353f62b8ee",
   "metadata": {},
   "source": [
    "Let's take a look to the entire __dataframe__ in the __current clean version__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19515e7e-9668-4c0c-ab01-e785e61810ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experienced support worker ppt cas</td>\n",
       "      <td>ability gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>wagga wagga wagga wagga riverina nsw</td>\n",
       "      <td>Aged &amp; Disability Support (Community Services ...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regional manager inspirehome</td>\n",
       "      <td>catholiccare tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>launceston launceston north east tas</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family support worker</td>\n",
       "      <td>community gro</td>\n",
       "      <td>$40 – $44 per hour</td>\n",
       "      <td>townsville northern qld</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Community Gro Inc is a community-based non-pro...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>https://www.seek.com.au/job/73832771?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cps case manager</td>\n",
       "      <td>open minds</td>\n",
       "      <td>$82k – 84k + super + salary packaging + benefits</td>\n",
       "      <td>nambour sunshine coast qld</td>\n",
       "      <td>Community Development (Community Services &amp; De...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>As a Case Manager for Coastal Supports at Open...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901240?type=stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intake worker</td>\n",
       "      <td>the centre for women co</td>\n",
       "      <td>$41 – $42 per hour</td>\n",
       "      <td>underwood brisbane qld</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>About Us and Our Team Culture   At The Centre ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73861002?type=stan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title                  company  \\\n",
       "0  experienced support worker ppt cas          ability gateway   \n",
       "1        regional manager inspirehome    catholiccare tasmania   \n",
       "2               family support worker            community gro   \n",
       "3                    cps case manager               open minds   \n",
       "4                       intake worker  the centre for women co   \n",
       "\n",
       "                                             salary  \\\n",
       "0                             $35.50 per hour [PPT]   \n",
       "1                                               NaN   \n",
       "2                                $40 – $44 per hour   \n",
       "3  $82k – 84k + super + salary packaging + benefits   \n",
       "4                                $41 – $42 per hour   \n",
       "\n",
       "                               location  \\\n",
       "0  wagga wagga wagga wagga riverina nsw   \n",
       "1  launceston launceston north east tas   \n",
       "2               townsville northern qld   \n",
       "3            nambour sunshine coast qld   \n",
       "4                underwood brisbane qld   \n",
       "\n",
       "                                          department       type  \\\n",
       "0  Aged & Disability Support (Community Services ...  Part time   \n",
       "1  Child Welfare, Youth & Family Services (Commun...  Full time   \n",
       "2  Child Welfare, Youth & Family Services (Commun...  Full time   \n",
       "3  Community Development (Community Services & De...  Full time   \n",
       "4  Child Welfare, Youth & Family Services (Commun...  Full time   \n",
       "\n",
       "                                         description  \\\n",
       "0  About usWe are an outcome focused NDIS service...   \n",
       "1  CatholicCare Tasmania is the primary social se...   \n",
       "2  Community Gro Inc is a community-based non-pro...   \n",
       "3  As a Case Manager for Coastal Supports at Open...   \n",
       "4  About Us and Our Team Culture   At The Centre ...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  Do you own or have regular access to a car?Whi...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "2  Which of the following statements best describ...  2024-02-19   \n",
       "3                                                NaN  2024-02-21   \n",
       "4  Which of the following statements best describ...  2024-02-20   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...  \n",
       "2  https://www.seek.com.au/job/73832771?type=stan...  \n",
       "3  https://www.seek.com.au/job/73901240?type=stan...  \n",
       "4  https://www.seek.com.au/job/73861002?type=stan...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display our current dataframe version\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85414198-d252-42e7-aa85-323d9c671c52",
   "metadata": {},
   "source": [
    "We have seen __lots of stopwords accross our dataset__.\n",
    "\n",
    "Our next step for cleaning is to remove all those stopwords.\n",
    "\n",
    "However, we must __pay attention to certain words that have important meaning and at the same time are considered stopwords__.\n",
    "\n",
    "- __Example:__ The most common meaning of __\"it\"__ is considered a stopword. However, \"it\" in job postings may refer to \"Information Technologies\".\n",
    "\n",
    "Let's start by identifying words of 1, 2, and 3 characters long, so we can __identify which ones to remove, and which ones to keep__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7fdc83-696a-4b3a-b235-05da92f397a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns: ['title', 'company', 'location']\n",
      "Finding words of length: [3, 2, 1]\n",
      "\n",
      "Words of length 1 to 3 on column 'title'\n",
      "- Words Length 1\n",
      "['a', 'd', 'f', 'i', 'k', 'l', 'm', 'n', 'p', 's', 't', 'v', 'w', 'x', 'y', '–', '’', '💡', '🤝']\n",
      "- Words Length 2\n",
      "['ah', 'ai', 'am', 'an', 'ao', 'ap', 'ar', 'as', 'at', 'au', 'av', 'ba', 'bb', 'bi', 'bp', 'ca', 'cc', 'ci', 'co', 'cx', 'dc', 'do', 'ds', 'ea', 'el', 'er', 'fm', 'fq', 'ft', 'gc', 'gm', 'go', 'gp', 'hc', 'hm', 'hr', 'ic', 'in', 'it', 'iv', 'ld', 'le', 'lf', 'lo', 'ma', 'mc', 'md', 'mq', 'mr', 'ms', 'mt', 'my', 'nd', 'no', 'nt', 'od', 'of', 'on', 'oo', 'or', 'ot', 'pa', 'pc', 'ph', 'pm', 'po', 'pt', 'pw', 'px', 'qa', 'qc', 'rd', 're', 'rn', 'sa', 'sc', 'sr', 'st', 'sw', 'to', 'tq', 'up', 'us', 'vp', 'wa', 'we', 'yr', '⚽️']\n",
      "- Words Length 3\n",
      "['abn', 'acm', 'act', 'age', 'ags', 'aid', 'ain', 'air', 'ald', 'alh', 'ali', 'all', 'ame', 'and', 'anz', 'aod', 'app', 'aps', 'apy', 'arc', 'are', 'aso', 'asx', 'atm', 'aus', 'aws', 'bar', 'bas', 'bay', 'bdm', 'bft', 'bgs', 'bid', 'bms', 'bom', 'box', 'bus', 'bws', 'cad', 'car', 'cas', 'cbd', 'ccs', 'cdc', 'ceo', 'cfo', 'cmt', 'cmy', 'cnc', 'cns', 'coo', 'cpc', 'cps', 'crk', 'crm', 'csl', 'ctp', 'daf', 'day', 'dev', 'dfo', 'dfv', 'div', 'dna', 'dog', 'dry', 'due', 'eca', 'ecm', 'egm', 'eho', 'ehs', 'elc', 'elm', 'emu', 'end', 'eoi', 'esd', 'esg', 'eso', 'euc', 'exp', 'far', 'fit', 'fix', 'fld', 'foi', 'fom', 'for', 'fpa', 'ftc', 'fte', 'fun', 'gap', 'gas', 'gcf', 'get', 'gin', 'gis', 'gmp', 'gpc', 'gym', 'hbc', 'hcp', 'her', 'his', 'hsp', 'hub', 'icp', 'ict', 'iga', 'imc', 'ims', 'inc', 'ion', 'isa', 'iso', 'itc', 'its', 'itt', 'ivf', 'jay', 'jmf', 'job', 'key', 'kit', 'lab', 'law', 'llc', 'lms', 'ltd', 'lvl', 'mcv', 'mep', 'mgr', 'mid', 'moe', 'msp', 'mth', 'net', 'new', 'nfp', 'ngs', 'nmr', 'nnw', 'non', 'now', 'nsw', 'nth', 'num', 'occ', 'off', 'one', 'ops', 'org', 'otc', 'ote', 'our', 'out', 'pae', 'pay', 'pcp', 'per', 'pet', 'phd', 'pmo', 'png', 'pos', 'ppt', 'pqe', 'pre', 'psu', 'pts', 'pty', 'qld', 'qsr', 'rab', 'ras', 'ray', 'rda', 'rep', 'rpd', 'rto', 'sap', 'sea', 'seo', 'ses', 'set', 'sil', 'sme', 'smp', 'sor', 'spa', 'spt', 'stp', 'sub', 'syd', 'tas', 'tax', 'tcs', 'tea', 'the', 'tmp', 'top', 'trc', 'try', 'ttw', 'two', 'uni', 'ute', 'van', 'vce', 'veg', 'vic', 'vps', 'web', 'wet', 'wfa', 'wfh', 'whs', 'whv', 'wmc', 'woy', 'yha', 'you']\n",
      "\n",
      "\n",
      "Words of length 1 to 2 on column 'company'\n",
      "- Words Length 1\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', '–', '’']\n",
      "- Words Length 2\n",
      "['ag', 'ah', 'ak', 'as', 'at', 'au', 'aw', 'ay', 'be', 'bp', 'br', 'bt', 'by', 'cg', 'ck', 'co', 'cs', 'da', 'de', 'do', 'dp', 'dr', 'ds', 'dt', 'dw', 'eg', 'em', 'ey', 'fc', 'fi', 'ft', 'ge', 'go', 'gp', 'hb', 'hd', 'hi', 'ho', 'hr', 'ic', 'in', 'ip', 'iq', 'it', 'jb', 'jd', 'jk', 'js', 'jv', 'ke', 'kh', 'ks', 'la', 'le', 'lf', 'lg', 'li', 'lj', 'lk', 'ly', 'mb', 'me', 'mj', 'mk', 'mq', 'mr', 'ms', 'mt', 'mv', 'mw', 'my', 'na', 'nc', 'nh', 'nl', 'no', 'nq', 'nt', 'nx', 'nz', 'of', 'on', 'op', 'oz', 'pc', 'pe', 'pl', 'pr', 'ps', 'pv', 'qb', 'qt', 'rd', 're', 'rk', 'rp', 'sa', 'sb', 'sc', 'se', 'sk', 'sm', 'st', 'ta', 'td', 'th', 'tj', 'tm', 'to', 'ts', 'ty', 'ua', 'up', 'uq', 'us', 'uu', 'va', 'wa', 'wb', 'wd', 'we', 'wh', 'ws', 'xm', 'xo', 'yd']\n",
      "\n",
      "\n",
      "Words of length 1 to 1 on column 'location'\n",
      "- Words Length 1\n",
      "['m']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return a list of lists, each list will contain the words of length 1, 2, 3... n\n",
    "def identify_words_len_1_to_n(df, colname, n):\n",
    "    # set n number of empty lists\n",
    "    words = [[] for _ in range(n)]\n",
    "    \n",
    "    # loop through unique values of the column\n",
    "    for value in df[colname].unique():\n",
    "        # if it's not a string, go to the next value\n",
    "        if not isinstance(value, str): continue\n",
    "        \n",
    "        # tokenize the value, loop through the words, if the word length its in range, add them to corresponding list\n",
    "        tokens = word_tokenize(value)\n",
    "        for word in tokens:\n",
    "            if len(word) <= n:\n",
    "                words[len(word)-1].append(word)\n",
    "                \n",
    "    # delete repeated values in the lists and sort them\n",
    "    words_len_1_to_n = [sorted(list(set(words_sublist))) for words_sublist in words]\n",
    "    \n",
    "    # print the results (each list)\n",
    "    print(\"Words of length 1 to\", n, \"on column '\"+colname+\"'\")\n",
    "    for i in range(n):\n",
    "        print(\"- Words Length\", i+1)\n",
    "        print(words_len_1_to_n[i])\n",
    "    return words_len_1_to_n\n",
    "\n",
    "def identify_words_len_1_to_n_columns(df, text_columns, ns):\n",
    "    # loop through the specified columns and identify the words of length 1 to n\n",
    "    words_per_col = []\n",
    "    for i, colname in enumerate(text_columns):\n",
    "        words_per_col.append(identify_words_len_1_to_n(df, colname, ns[i]))\n",
    "        print(\"\\n\")\n",
    "    return words_per_col\n",
    "\n",
    "# define the word lengths per text column\n",
    "text_cols = ['title', 'company', 'location']\n",
    "word_max_lens = [3, 2, 1]\n",
    "print(\"Text columns:\", text_cols, end='\\n')\n",
    "print(\"Finding words of length:\", word_max_lens, end='\\n\\n')\n",
    "words_per_col = identify_words_len_1_to_n_columns(df, text_cols, word_max_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee8744-1d68-4a7c-8a6a-9a03916e76d3",
   "metadata": {},
   "source": [
    "For our column title all words length 1 need to be removed, as they don't bring any value to our analysis.\n",
    "\n",
    "From our 2 length words, we will remove most of them except for the following common job accronyms:\n",
    "- __hr__ : Human Resources\n",
    "- __it__: Information Technology\n",
    "\n",
    "From the 3 length words, again we will remove most of them except for the following:\n",
    "- __ceo__: Chief Executive Officer\n",
    "- __cfo__: Chief Financial Officer\n",
    "- __aws__: Amazon Web Services\n",
    "- __pmo__: Project Management Office\n",
    "- __pcp__: Primary Care Physician\n",
    "- __crm__: Customer Relationship Management\n",
    "- __sap__: System Applications (ERP leader)\n",
    "- __app__: application\n",
    "- __dev__: developer\n",
    "- __lab__: laboratory\n",
    "- __web__: internet\n",
    "- __law__: self-explanatory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca5431-4393-4836-9162-022294df3078",
   "metadata": {},
   "source": [
    "Now that we have identified more words to remove, let's __implement a function that removes all stopwords__ on top of the extra ones.\n",
    "\n",
    "Let's also keep in mind the __list of values that should not be removed__ (from the same analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d19419-9f71-491b-94ad-a9b50f0599ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import flatten # convert nested list into 1D list\n",
    "\n",
    "def set_additional_stopwords(words_per_col):\n",
    "    # set our additional stopwords making use of the identified 1 to 3 length words for each column\n",
    "    additionals = []\n",
    "    for column_words in words_per_col:\n",
    "        # make sure we only have unique values by using set\n",
    "        additionals.append(list(set(flatten(column_words))))\n",
    "    return additionals\n",
    "\n",
    "additionals = set_additional_stopwords(words_per_col) # pass our list of lists defined in the previous code block\n",
    "\n",
    "# set the exceptions manually based on our word length analysis\n",
    "exceptions = ['hr', 'it', 'ceo', 'cfo', 'aws', 'pmo', 'pcp', 'crm', 'sap', 'app', 'dev', 'lab', 'web', 'law']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9927e49-5f19-4935-a839-952683b4c775",
   "metadata": {},
   "source": [
    "Now let's __implement a new class that stores our stopwords removal methods__.\n",
    "\n",
    "We will use this class to perform the stopwords removal __taking into account our additional stopwords and exceptions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8d54a3-735f-44bf-ade3-76d45eacc377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing stopwords on column 'title'\n",
      "# Unique values with stopwords: 5541\n",
      "# Unique values without stopwords: 5398\n",
      "% of unique values reduction: 2.58 %\n",
      "\n",
      "Removing stopwords on column 'company'\n",
      "# Unique values with stopwords: 4965\n",
      "# Unique values without stopwords: 4925\n",
      "% of unique values reduction: 0.81 %\n",
      "\n",
      "Removing stopwords on column 'location'\n",
      "# Unique values with stopwords: 1448\n",
      "# Unique values without stopwords: 1448\n",
      "% of unique values reduction: 0.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NLP_stopwords():\n",
    "    \n",
    "    def remove_stopwords_columns(self, df, colnames, additionals=[], exceptions=[]):\n",
    "        # remove stopwords from a set of textual columns passed as parameters\n",
    "        if additionals == []:\n",
    "            additionals = [[] for _ in range(len(colnames))]\n",
    "        if len(colnames) != len(additionals):\n",
    "            raise Exception(\"Column names length must be equal to the additional stop words.\")\n",
    "\n",
    "        # remove stopwords on specified columns\n",
    "        for i, colname in enumerate(colnames):\n",
    "            self.remove_stopwords_column(df, colname, additionals[i], exceptions)\n",
    "\n",
    "    def remove_stopwords_column(self, df, colname, additional=[], exceptions=[]):\n",
    "        print(\"Removing stopwords on column '\" + colname + \"'\")\n",
    "        nunique = df[colname].nunique()\n",
    "        print(\"# Unique values with stopwords:\", df[colname].nunique())        \n",
    "        \n",
    "        # loop through unique values of the column\n",
    "        for value in df[colname].unique():\n",
    "            # make sure the value is a string\n",
    "            if not isinstance(value, str): continue\n",
    "            \n",
    "            # tokenize the unique column value\n",
    "            tokens = word_tokenize(value)\n",
    "\n",
    "            # remove stopwords\n",
    "            self.remove_stopwords_tokens(tokens, additional, exceptions)\n",
    "\n",
    "            # update df value in place\n",
    "            df[colname].replace(value, ' '.join(tokens), inplace=True)\n",
    "        \n",
    "        new_nunique = df[colname].nunique()\n",
    "        print(\"# Unique values without stopwords:\", df[colname].nunique())\n",
    "        print(\"% of unique values reduction:\", round(100 - (new_nunique*100/nunique),2), \"%\", end=\"\\n\\n\")\n",
    "\n",
    "    def remove_stopwords_tokens(self, tokens, additional=[], exceptions=[]):\n",
    "        # remove stopwords on a list of word tokens\n",
    "        i = 0\n",
    "        # add the additional parameter stopwords\n",
    "        total_stopwords = stopwords.words('english') + additional\n",
    "        while i < len(tokens):\n",
    "            word = tokens[i]\n",
    "            # if the word is in exceptions, don't remove it\n",
    "            if word in total_stopwords and word not in exceptions:\n",
    "                tokens.pop(i)\n",
    "                i -= 1\n",
    "            i += 1\n",
    "\n",
    "nlp = NLP_stopwords()\n",
    "text_cols = ['title', 'company', 'location']\n",
    "nlp.remove_stopwords_columns(df, text_cols, additionals, exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d1134-6300-4bd4-abf8-cac16ab542af",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's __find the most frequent bigrams and trigrams__ for each column.\n",
    "\n",
    "Once again, we will __define a third NLP class to store our new implemented methods__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f51377e-0e9f-4a0b-8503-e7f015886c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 unigrams of column 'title':\n",
      "[('manager', 1649), ('officer', 1274), ('assistant', 1045), ('support', 590), ('sales', 515), ('engineer', 430), ('coordinator', 423), ('administration', 422), ('senior', 410), ('accountant', 350)]\n",
      "\n",
      "Top 10 bigrams of column 'title':\n",
      "[(('property', 'manager'), 199), (('support', 'officer'), 167), (('general', 'manager'), 153), (('administration', 'officer'), 142), (('administration', 'assistant'), 141), (('people', 'culture'), 138), (('business', 'partner'), 138), (('customer', 'service'), 119), (('part', 'time'), 116), (('human', 'resources'), 115)]\n",
      "\n",
      "Top 10 trigrams of column 'title':\n",
      "[(('chief', 'executive', 'officer'), 77), (('accounts', 'payable', 'officer'), 73), (('hr', 'business', 'partner'), 46), (('business', 'development', 'manager'), 45), (('it', 'support', 'officer'), 44), (('real', 'estate', 'sales'), 44), (('administration', 'assistant', 'administration'), 36), (('retail', 'sales', 'assistant'), 36), (('property', 'manager', 'property'), 33), (('chief', 'financial', 'officer'), 33)]\n",
      "\n",
      "-----------------------------------\n",
      "Top 10 unigrams of column 'company':\n",
      "[('ltd', 1404), ('pty', 1330), ('australia', 678), ('group', 628), ('recruitment', 468), ('health', 348), ('private', 332), ('services', 330), ('advertiser', 286), ('limited', 270)]\n",
      "\n",
      "Top 10 bigrams of column 'company':\n",
      "[(('pty', 'ltd'), 1242), (('private', 'advertiser'), 286), (('australia', 'pty'), 203), (('real', 'estate'), 110), (('pty', 'limited'), 84), (('group', 'pty'), 80), (('sharp', 'carter'), 68), (('city', 'council'), 66), (('services', 'pty'), 60), (('ltd', 'private'), 42)]\n",
      "\n",
      "Top 10 trigrams of column 'company':\n",
      "[(('australia', 'pty', 'ltd'), 174), (('group', 'pty', 'ltd'), 56), (('services', 'pty', 'ltd'), 55), (('pty', 'ltd', 'private'), 42), (('ltd', 'private', 'advertiser'), 42), (('recruitment', 'pty', 'ltd'), 36), (('australian', 'federal', 'police'), 34), (('pty', 'ltd', 'australian'), 31), (('australia', 'pty', 'limited'), 28), (('recruitment', 'real', 'estate'), 27)]\n",
      "\n",
      "-----------------------------------\n",
      "Top 10 unigrams of column 'location':\n",
      "[('nsw', 3130), ('qld', 2421), ('sydney', 2287), ('vic', 2221), ('melbourne', 1793), ('brisbane', 1372), ('coast', 1130), ('wa', 904), ('perth', 778), ('north', 566)]\n",
      "\n",
      "Top 10 bigrams of column 'location':\n",
      "[(('sydney', 'nsw'), 2226), (('melbourne', 'vic'), 1718), (('brisbane', 'qld'), 1335), (('perth', 'wa'), 723), (('coast', 'qld'), 593), (('adelaide', 'sa'), 427), (('coast', 'nsw'), 349), (('gold', 'coast'), 314), (('nsw', 'sydney'), 264), (('newcastle', 'maitland'), 237)]\n",
      "\n",
      "Top 10 trigrams of column 'location':\n",
      "[(('gold', 'coast', 'qld'), 314), (('nsw', 'sydney', 'nsw'), 262), (('newcastle', 'maitland', 'hunter'), 237), (('maitland', 'hunter', 'nsw'), 237), (('sydney', 'nsw', 'sydney'), 216), (('qld', 'sydney', 'nsw'), 201), (('vic', 'sydney', 'nsw'), 192), (('nsw', 'melbourne', 'vic'), 188), (('nsw', 'brisbane', 'qld'), 183), (('sunshine', 'coast', 'qld'), 167)]\n",
      "\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "\n",
    "class NLP_ngrams():\n",
    "    def merge_documents_into_list(self, df, colname):\n",
    "        # store all column values into a list of strings\n",
    "        lst = []\n",
    "        for row in df[colname]:\n",
    "            if not isinstance(row, str): continue\n",
    "            lst += word_tokenize(row)\n",
    "        return lst\n",
    "    \n",
    "    def get_column_n_most_frequent_unigrams(self, df, colname, n):\n",
    "        lst = self.merge_documents_into_list(df, colname)\n",
    "        counts = {}\n",
    "        for word in lst: counts[word] = counts.get(word, 0) + 1\n",
    "        # return list of tuples (unigram, frequency) sorted by the frequency in decreasing order\n",
    "        return sorted(counts.items(), key=lambda x:x[1], reverse=True)[:n]\n",
    "        \n",
    "    def get_column_n_most_frequent_bigrams(self, df, colname, n, freq_filter=10):\n",
    "        lst = self.merge_documents_into_list(df, colname)\n",
    "        bcf = BigramCollocationFinder.from_words(lst)\n",
    "        bcf.apply_freq_filter(freq_filter) # filter bigrams that won't repeat at least 10 times\n",
    "        # return list of tuples (bigram, frequency) sorted by the frequency in decreasing order\n",
    "        return sorted(list(bcf.ngram_fd.items()), key=lambda x:x[1], reverse=True)[:n]\n",
    "    \n",
    "    def get_column_n_most_frequent_trigrams(self, df, colname, n, freq_filter=10):\n",
    "        lst = self.merge_documents_into_list(df, colname)\n",
    "        tcf = TrigramCollocationFinder.from_words(lst)\n",
    "        tcf.apply_freq_filter(freq_filter) # filter trigrams that won't repeat at least 10 times\n",
    "        # return list of tuples (trigram, frequency) sorted by the frequency in decreasing order\n",
    "        return sorted(list(tcf.ngram_fd.items()), key=lambda x:x[1], reverse=True)[:n]\n",
    "\n",
    "    def get_top_x_most_frequent_ngrams_of_column(self, df, colname, x):\n",
    "        # get the most frequent n-grams (uni, bi, and tri) within the column values\n",
    "        top_x_unigrams = self.get_column_n_most_frequent_unigrams(df, colname, x)\n",
    "        top_x_bigrams = self.get_column_n_most_frequent_bigrams(df, colname, x)\n",
    "        top_x_trigrams = self.get_column_n_most_frequent_trigrams(df, colname, x)\n",
    "        top_x_ngrams = [top_x_unigrams, top_x_bigrams, top_x_trigrams]\n",
    "        return top_x_ngrams\n",
    "    \n",
    "def get_top_x_most_frequent_ngrams_of_columns(df, colnames, x_cols):\n",
    "    ngram_names = {1:'unigrams', 2:'bigrams', 3:'trigrams'}\n",
    "    nlp = NLP_ngrams()\n",
    "    ngrams = {}\n",
    "    # loop through column names, display only top 10 most frequent n-grams, but save the top x ngrams passed as parameters\n",
    "    for i in range(len(colnames)):\n",
    "        # save top x most frequent ngrams of the column\n",
    "        column_ngrams = nlp.get_top_x_most_frequent_ngrams_of_column(df, colnames[i], x_cols[i])\n",
    "        \n",
    "        # save it in a dictionary (key = column name, value = list of lists of ngrams)\n",
    "        ngrams[colnames[i]] = column_ngrams\n",
    "        \n",
    "        # display only top 10 ngrams for each column\n",
    "        for j in range(1,4):\n",
    "            print(\"Top 10\", ngram_names[j], \"of column '\"+colnames[i]+\"':\")\n",
    "            print(column_ngrams[j-1][:10], end=\"\\n\\n\")\n",
    "        print(\"-\"*35)\n",
    "    \n",
    "    return ngrams # return the dictionary (keys = column names, values = list of ngrams)\n",
    "        \n",
    "colnames = ['title', 'company', 'location']\n",
    "xs = [200 for _ in range(len(text_cols))] # we will get top 200 of every column\n",
    "ngrams_per_column = get_top_x_most_frequent_ngrams_of_columns(df, colnames, xs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09d3ab-664d-47f1-85bf-2a67ae53bd37",
   "metadata": {},
   "source": [
    "We have seen some of the most frequent n-grams (unigrams, bigrams, and trigrams) for our columns.\n",
    "\n",
    "Let's __replace the each column values with the most frequent n-grams found for each column__.\n",
    "\n",
    "This will serve us as a method to standardize values and reduce the number of categorical unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2fe59c7-c4ad-475d-84ae-f7dd27bd3212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing column 'title':\n",
      "# Unique Values before replacement: 5398\n",
      "# Unique Values after replacement: 610\n",
      "\n",
      "Replacing column 'company':\n",
      "# Unique Values before replacement: 4925\n",
      "# Unique Values after replacement: 1732\n",
      "\n",
      "Replacing column 'location':\n",
      "# Unique Values before replacement: 1448\n",
      "# Unique Values after replacement: 87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NLP_replace_values():\n",
    "    def replace_column_values_based_on_ngrams(self, df, colname, ngrams):\n",
    "        # save all ngrams into a list for search purposes\n",
    "        list_unigrams = [[tuple_[0]] for tuple_ in ngrams[0]] \n",
    "        list_bigrams = [list(tuple_[0])  for tuple_ in ngrams[1]]\n",
    "        list_trigrams = [list(tuple_[0])  for tuple_ in ngrams[2]]\n",
    "        list_ngrams = [list_unigrams, list_bigrams, list_trigrams]\n",
    "            \n",
    "        # loop through column rows and replace the value with most common ngram\n",
    "        for i, value in enumerate(df[colname]):\n",
    "            # tokenize row value\n",
    "            if not isinstance(value, str): continue\n",
    "            tokens = word_tokenize(value)\n",
    "            \n",
    "            # save most frequent ngram, and its frequency for comparing purposes\n",
    "            highest_ngram, highest_ngram_frequency = \"\", -1\n",
    "            \n",
    "            # loop through ngrams (start by looking for trigrams within the tokenized words, if not found, search for bigrams, finally unigrams)\n",
    "            for j in range(2,-1,-1):\n",
    "                # list of unigrams, bigrams, or trigrams depending on iteration\n",
    "                j_ngrams = list_ngrams[j]\n",
    "                \n",
    "                # loop through tokenized words\n",
    "                for k in range(len(tokens) - j):\n",
    "                    # set current ngram, if ngram not found on the top most frequent, skip iteration\n",
    "                    ngram = tokens[k : k + j + 1]\n",
    "                    if ngram not in j_ngrams: continue\n",
    "                    \n",
    "                    # otherwise, if found, get the frequency of the ngram\n",
    "                    ngram_frequency = ngrams[j][j_ngrams.index(ngram)][1]\n",
    "                    \n",
    "                    # if the frequency is higher, replace values\n",
    "                    if ngram_frequency > highest_ngram_frequency:\n",
    "                        highest_ngram, highest_ngram_frequency = ngram, ngram_frequency\n",
    "                        \n",
    "                # if we found a trigram, we don't need to look for bigrams or unigrams\n",
    "                # if we found a bigram, we don't need to look for unigrams\n",
    "                if highest_ngram != \"\":\n",
    "                    break\n",
    "            # finally replace the row value with the frequent ngram identified\n",
    "            if highest_ngram != \"\":\n",
    "                df.loc[i, colname] = ' '.join(highest_ngram)\n",
    "    \n",
    "    def replace_columns_values_based_on_ngrams(self, df, colnames, ngrams_columns):\n",
    "        # apply value replacement based o ngrams for a set of columns\n",
    "        for colname in colnames:\n",
    "            print(\"Replacing column '\"+colname+\"':\")\n",
    "            print(\"# Unique Values before replacement:\", df[colname].nunique())\n",
    "            self.replace_column_values_based_on_ngrams(df, colname, ngrams_columns[colname])\n",
    "            print(\"# Unique Values after replacement:\", df[colname].nunique(), end=\"\\n\\n\")\n",
    "\n",
    "nlp = NLP_replace_values()\n",
    "text_cols = ['title', 'company', 'location']\n",
    "nlp.replace_columns_values_based_on_ngrams(df, text_cols, ngrams_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a832a4-0825-4885-910b-067aef681c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support worker</td>\n",
       "      <td>ability gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>wagga wagga wagga</td>\n",
       "      <td>Aged &amp; Disability Support (Community Services ...</td>\n",
       "      <td>Part time</td>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regional manager</td>\n",
       "      <td>tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>launceston north east</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services (Commun...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title          company                 salary  \\\n",
       "0    support worker  ability gateway  $35.50 per hour [PPT]   \n",
       "1  regional manager         tasmania                    NaN   \n",
       "\n",
       "                location                                         department  \\\n",
       "0      wagga wagga wagga  Aged & Disability Support (Community Services ...   \n",
       "1  launceston north east  Child Welfare, Youth & Family Services (Commun...   \n",
       "\n",
       "        type                                        description  \\\n",
       "0  Part time  About usWe are an outcome focused NDIS service...   \n",
       "1  Full time  CatholicCare Tasmania is the primary social se...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  Do you own or have regular access to a car?Whi...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.seek.com.au/job/73909631?type=prom...  \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b06239-1512-4005-a8d7-a143b8607173",
   "metadata": {},
   "source": [
    "Now our columns 'title', 'company', and 'location' are cleaned with reduced unique values.\n",
    "\n",
    "Let's proceed with __'department'__ that comes in the following format: __'department (industry)'__ where we can __extract the industry into a new column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "124de49d-e987-4eda-accb-ad5106a2477f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# functions to extract the department and industry\n",
    "def get_industry(text):\n",
    "    # pattern to catch a group inside parenthesis\n",
    "    matches = re.findall('\\((.+?)\\)', text)\n",
    "    # some have 2 fields in it return just the first one\n",
    "    return matches[0]\n",
    "\n",
    "def get_department(text):\n",
    "    # pattern to catch a group inside parenthesis\n",
    "    splits = text.split('(')\n",
    "    # some have 2 fields in it return just the first one\n",
    "    return splits[0].strip()\n",
    "\n",
    "# creating 2 new columns\n",
    "df['industry'] = df['department'].apply(get_industry)\n",
    "df['department'] = df['department'].apply(get_department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bbd8ca0-ef48-445f-b65c-3006f9261aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of industries: 26\n",
      "Number of departments: 206\n",
      "Industries:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accounting                                919\n",
       "Manufacturing, Transport & Logistics      732\n",
       "Administration & Office Support           648\n",
       "Information & Communication Technology    628\n",
       "Healthcare & Medical                      571\n",
       "Retail & Consumer Products                564\n",
       "Community Services & Development          562\n",
       "Real Estate & Property                    562\n",
       "Science & Technology                      556\n",
       "CEO & General Management                  556\n",
       "Human Resources & Recruitment             554\n",
       "Legal                                     552\n",
       "Insurance & Superannuation                552\n",
       "Sport & Recreation                        550\n",
       "Engineering                               550\n",
       "Marketing & Communications                302\n",
       "Sales                                     296\n",
       "Call Centre & Customer Service             61\n",
       "Farming, Animals & Conservation            26\n",
       "Trades & Services                          24\n",
       "Hospitality & Tourism                      11\n",
       "Education & Training                        8\n",
       "Construction                                7\n",
       "Government & Defence                        5\n",
       "Mining, Resources & Energy                  3\n",
       "Banking & Financial Services                1\n",
       "Name: industry, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of industries:\", df['industry'].nunique())\n",
    "print(\"Number of departments:\", df['department'].nunique())\n",
    "print(\"Industries:\")\n",
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9979d-85b8-4d7e-ac88-15c08146a25c",
   "metadata": {},
   "source": [
    "Now we have extracted the industries into a separate column.\n",
    "\n",
    "Let's proceed with the column __'posted_date'__.\n",
    "\n",
    "We will process it into the __number of days elapsed from the posted date until today__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "123a138f-27d8-4802-a648-93c45a3bf83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# casting posted_date as datetime\n",
    "df['posted_date'] = pd.to_datetime(df['posted_date'])\n",
    "\n",
    "# function to calculate the number of days elapsed since the posted date\n",
    "def get_days_ago(date):\n",
    "    today = datetime.now()\n",
    "    return (today - date).days\n",
    "\n",
    "# create new column of days elapsed\n",
    "df['days_ago'] = df['posted_date'].apply(get_days_ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7e5737c-7ab0-43ee-a5fc-a1ecc621f195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'days_ago' unique values: 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23      2464\n",
       "24      2241\n",
       "25      1475\n",
       "28       787\n",
       "29       507\n",
       "        ... \n",
       "1642       1\n",
       "1282       1\n",
       "48         1\n",
       "532        1\n",
       "1792       1\n",
       "Name: days_ago, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of 'days_ago' unique values:\", df['days_ago'].nunique())\n",
    "df['days_ago'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e618a55c-1899-4c47-9c34-2e7f5564e3cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can identify some outliers from the value counts, but we will get back to them on future steps.\n",
    "\n",
    "Let's proceed with __'type' column__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9956c0b-d055-4b07-b1ff-3867136869a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Full time                                               7044\n",
       "Casual/Vacation                                          965\n",
       "Part time                                                959\n",
       "Contract/Temp                                            826\n",
       "Contract/Temp, Casual/Vacation, Full time, Part time       2\n",
       "Casual/Vacation, Full time                                 2\n",
       "Contract/Temp, Casual/Vacation, Part time                  1\n",
       "Contract/Temp, Part time                                   1\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values and counts of column 'type'\n",
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f077f8f-3265-4708-9286-edd8bcd7cbac",
   "metadata": {},
   "source": [
    "For the type column we see some few outliers (around 6) and the rest of columns reside only within: __'Full time', 'Casual/Vacation', 'Part time', and 'Contract/Temp'.__\n",
    "\n",
    "We __don't need further cleaning for this column__, however, we will have to deal with the few outliers on later steps.\n",
    "\n",
    "Let's continue with the __'salary'__ column.\n",
    "\n",
    "- Number of working weeks in a year: 52\n",
    "- Full-time number of hours per week: 40\n",
    "- Minimum wage in australia hourly: $23.23\n",
    "\n",
    "- Minimum wage in australia annually: $45,905.60\n",
    "\n",
    "We have mixed salaries in hourly and annually rate and __some jobs are part-time or casual.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4bfa17c6-cbc2-4957-b909-5722aceb3973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_number(str_num):\n",
    "    num = str_num.replace(',','') # delete commas\n",
    "    num = num.replace('k', '000') # convert letter k into thousands\n",
    "    num = num.replace('K', '000') # convert letter K into thousands\n",
    "    return float(num)\n",
    "\n",
    "def segment_number(num):\n",
    "    if num < 0: return 0 # floor negative values if they exist\n",
    "\n",
    "    # if it's an hourly rate we convert it into yearly (40 hours per week * 52 working weeks in a year)\n",
    "    if num >= 0  and num < 100: return num * 40 * 52 \n",
    "    \n",
    "    # threshold of hourly rate set at 100 after analyzing our data, greater numbers often refer to yearly rates in thosuands up until 500K\n",
    "    if num >= 100 and num < 500: return num * 1000\n",
    "\n",
    "    # min yearly wage: $45K; however some jobs are part-time or casual, we will leave them as-is\n",
    "    if num >= 500: return num\n",
    "    \n",
    "def extract_min_salary(salary):\n",
    "    # keep null values as they are\n",
    "    if not isinstance(salary, str): return salary\n",
    "\n",
    "    # extract raw numbers as strings 'd+,d*.d*', they may have a letter 'k' at the end\n",
    "    raw_numbers = re.findall('\\d+[.,]?\\d*[.,]?\\d*[kK]?', salary)\n",
    "    \n",
    "    # if salary didn't contain numbers then we return a null value\n",
    "    if raw_numbers == []: return np.nan\n",
    "    \n",
    "    # clean and segment numbers depending on hourly or yearly rates\n",
    "    clean_numbers = list(map(clean_number, raw_numbers))\n",
    "    numbers = list(map(segment_number, clean_numbers))\n",
    "    return min(numbers)\n",
    "\n",
    "def extract_max_salary(salary):\n",
    "    # same as extract_min_salary but returns the max number found\n",
    "    if not isinstance(salary, str): return salary\n",
    "    raw_numbers = re.findall('\\d+[.,]?\\d*[.,]?\\d*[kK]?', salary)\n",
    "    if raw_numbers == []: return np.nan\n",
    "    clean_numbers = list(map(clean_number, raw_numbers))\n",
    "    numbers = list(map(segment_number, clean_numbers))\n",
    "    return int(max(numbers))\n",
    "\n",
    "# create new numerical columns based on yearly salary rates extracted from categorical column 'salary'\n",
    "df['min_salary'] = df['salary'].apply(extract_min_salary)\n",
    "df['max_salary'] = df['salary'].apply(extract_max_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9febc9a9-88d8-4e63-8914-abd7cfffc69c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>company_questions</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>link</th>\n",
       "      <th>industry</th>\n",
       "      <th>days_ago</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support worker</td>\n",
       "      <td>ability gateway</td>\n",
       "      <td>$35.50 per hour [PPT]</td>\n",
       "      <td>wagga wagga wagga</td>\n",
       "      <td>Aged &amp; Disability Support</td>\n",
       "      <td>Part time</td>\n",
       "      <td>About usWe are an outcome focused NDIS service...</td>\n",
       "      <td>Do you own or have regular access to a car?Whi...</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909631?type=prom...</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>73840.0</td>\n",
       "      <td>73840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regional manager</td>\n",
       "      <td>tasmania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>launceston north east</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services</td>\n",
       "      <td>Full time</td>\n",
       "      <td>CatholicCare Tasmania is the primary social se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73909232?type=prom...</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>support worker</td>\n",
       "      <td>community</td>\n",
       "      <td>$40 – $44 per hour</td>\n",
       "      <td>townsville northern qld</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Community Gro Inc is a community-based non-pro...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>https://www.seek.com.au/job/73832771?type=stan...</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>25</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>91520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case manager</td>\n",
       "      <td>open minds</td>\n",
       "      <td>$82k – 84k + super + salary packaging + benefits</td>\n",
       "      <td>sunshine coast qld</td>\n",
       "      <td>Community Development</td>\n",
       "      <td>Full time</td>\n",
       "      <td>As a Case Manager for Coastal Supports at Open...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>https://www.seek.com.au/job/73901240?type=stan...</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>84000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worker</td>\n",
       "      <td>centre</td>\n",
       "      <td>$41 – $42 per hour</td>\n",
       "      <td>brisbane qld</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services</td>\n",
       "      <td>Full time</td>\n",
       "      <td>About Us and Our Team Culture   At The Centre ...</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>https://www.seek.com.au/job/73861002?type=stan...</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>85280.0</td>\n",
       "      <td>87360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title          company  \\\n",
       "0    support worker  ability gateway   \n",
       "1  regional manager         tasmania   \n",
       "2    support worker        community   \n",
       "3      case manager       open minds   \n",
       "4            worker           centre   \n",
       "\n",
       "                                             salary                 location  \\\n",
       "0                             $35.50 per hour [PPT]        wagga wagga wagga   \n",
       "1                                               NaN    launceston north east   \n",
       "2                                $40 – $44 per hour  townsville northern qld   \n",
       "3  $82k – 84k + super + salary packaging + benefits       sunshine coast qld   \n",
       "4                                $41 – $42 per hour             brisbane qld   \n",
       "\n",
       "                               department       type  \\\n",
       "0               Aged & Disability Support  Part time   \n",
       "1  Child Welfare, Youth & Family Services  Full time   \n",
       "2  Child Welfare, Youth & Family Services  Full time   \n",
       "3                   Community Development  Full time   \n",
       "4  Child Welfare, Youth & Family Services  Full time   \n",
       "\n",
       "                                         description  \\\n",
       "0  About usWe are an outcome focused NDIS service...   \n",
       "1  CatholicCare Tasmania is the primary social se...   \n",
       "2  Community Gro Inc is a community-based non-pro...   \n",
       "3  As a Case Manager for Coastal Supports at Open...   \n",
       "4  About Us and Our Team Culture   At The Centre ...   \n",
       "\n",
       "                                   company_questions posted_date  \\\n",
       "0  Do you own or have regular access to a car?Whi...  2024-02-21   \n",
       "1                                                NaN  2024-02-21   \n",
       "2  Which of the following statements best describ...  2024-02-19   \n",
       "3                                                NaN  2024-02-21   \n",
       "4  Which of the following statements best describ...  2024-02-20   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.seek.com.au/job/73909631?type=prom...   \n",
       "1  https://www.seek.com.au/job/73909232?type=prom...   \n",
       "2  https://www.seek.com.au/job/73832771?type=stan...   \n",
       "3  https://www.seek.com.au/job/73901240?type=stan...   \n",
       "4  https://www.seek.com.au/job/73861002?type=stan...   \n",
       "\n",
       "                           industry  days_ago  min_salary  max_salary  \n",
       "0  Community Services & Development        23     73840.0     73840.0  \n",
       "1  Community Services & Development        23         NaN         NaN  \n",
       "2  Community Services & Development        25     83200.0     91520.0  \n",
       "3  Community Services & Development        23     82000.0     84000.0  \n",
       "4  Community Services & Development        24     85280.0     87360.0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3a594777-e37f-425b-8655-c2863001178e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_safe = df.copy() # checkpoint our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4e35a-d8ca-44eb-9822-9478f9e36fa4",
   "metadata": {},
   "source": [
    "We succesfully extracted the min and max yearly salary rate for all salary values.\n",
    "\n",
    "Now we will drop the following columns as they don't bring value to our analysis for now.\n",
    "- 'salary' (already processed)\n",
    "- 'description'\n",
    "- 'company_questions'\n",
    "- 'posted_date' (already processed)\n",
    "- 'link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3e48de19-55d8-431a-a618-4cec383f2531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop selected columns\n",
    "df.drop(['salary', 'description', 'company_questions', 'posted_date', 'link'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "87c173dc-1b47-48c0-88f6-5d5ec8f21ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>industry</th>\n",
       "      <th>days_ago</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support worker</td>\n",
       "      <td>ability gateway</td>\n",
       "      <td>wagga wagga wagga</td>\n",
       "      <td>Aged &amp; Disability Support</td>\n",
       "      <td>Part time</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>73840.0</td>\n",
       "      <td>73840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regional manager</td>\n",
       "      <td>tasmania</td>\n",
       "      <td>launceston north east</td>\n",
       "      <td>Child Welfare, Youth &amp; Family Services</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Community Services &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title          company               location  \\\n",
       "0    support worker  ability gateway      wagga wagga wagga   \n",
       "1  regional manager         tasmania  launceston north east   \n",
       "\n",
       "                               department       type  \\\n",
       "0               Aged & Disability Support  Part time   \n",
       "1  Child Welfare, Youth & Family Services  Full time   \n",
       "\n",
       "                           industry  days_ago  min_salary  max_salary  \n",
       "0  Community Services & Development        23     73840.0     73840.0  \n",
       "1  Community Services & Development        23         NaN         NaN  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec9b00-94cf-4766-b84d-ec641f74d15c",
   "metadata": {},
   "source": [
    "Now that we have more clean and accurate data, let's __revise some metrics again by re-using our initial methods__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "23408140-6d0e-4ffc-bca0-1cc1c48d36ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 9800\n",
      "Number of Columns: 9\n",
      "Index(['title', 'company', 'location', 'department', 'type', 'industry',\n",
      "       'days_ago', 'min_salary', 'max_salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "display_shape_and_colnames(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4b0a31d2-81c6-4af5-8068-d8df9e87bbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Missing Values\n",
      "title            0\n",
      "company          0\n",
      "location         0\n",
      "department       0\n",
      "type             0\n",
      "industry         0\n",
      "days_ago         0\n",
      "min_salary    5846\n",
      "max_salary    5846\n",
      "dtype: int64\n",
      "\n",
      "% Missing Values\n",
      "title          0.000000\n",
      "company        0.000000\n",
      "location       0.000000\n",
      "department     0.000000\n",
      "type           0.000000\n",
      "industry       0.000000\n",
      "days_ago       0.000000\n",
      "min_salary    59.653061\n",
      "max_salary    59.653061\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7d42d902-c5c3-4b0d-9c98-b7b3cab3d3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Duplicated Values\n",
      "1331\n",
      "\n",
      "% Duplicated Values\n",
      "13.581632653061224\n"
     ]
    }
   ],
   "source": [
    "check_duplicated_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "80bda1e4-89bd-471a-85e3-50029599ba92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Values per Column\n",
      "'title' # of unique values: 610\n",
      "'company' # of unique values: 1732\n",
      "'location' # of unique values: 87\n",
      "'department' # of unique values: 206\n",
      "'type' # of unique values: 8\n",
      "'industry' # of unique values: 26\n",
      "'days_ago' # of unique values: 95\n",
      "'min_salary' # of unique values: 662\n",
      "'max_salary' # of unique values: 816\n",
      "\n",
      "% Unique Values per Column\n",
      "'title' % of unique values: 6.22 %\n",
      "'company' % of unique values: 17.67 %\n",
      "'location' % of unique values: 0.89 %\n",
      "'department' % of unique values: 2.1 %\n",
      "'type' % of unique values: 0.08 %\n",
      "'industry' % of unique values: 0.27 %\n",
      "'days_ago' % of unique values: 0.97 %\n",
      "'min_salary' % of unique values: 6.76 %\n",
      "'max_salary' % of unique values: 8.33 %\n"
     ]
    }
   ],
   "source": [
    "check_nunique_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023cc58-5da5-40d0-8c53-dd01c5460b55",
   "metadata": {},
   "source": [
    "We will __deal now with the missing values__ that we only have in salary columns.\n",
    "\n",
    "Our approach is to apply __imputation because we have more than half missing data__ (so we can not simply drop them), we will use the existing half to predict the missing values.\n",
    "\n",
    "We will also __take into account the 'title' or 'industry' of the job__ for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0dbacd83-2d80-4027-9b6c-cea00356b937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Salary median per job title\n",
      "title\n",
      "                                             NaN\n",
      "account                                  60000.0\n",
      "account executive                        80000.0\n",
      "account executive insurance              90000.0\n",
      "account manager                          90000.0\n",
      "                                          ...   \n",
      "workers                                  63544.0\n",
      "young carer connector                     8528.0\n",
      "youth                                        NaN\n",
      "youth worker                             81436.5\n",
      "zone directors aboriginal identified    144800.0\n",
      "Name: min_salary, Length: 610, dtype: float64\n",
      "------------------------------\n",
      "Max Salary median per title\n",
      "title\n",
      "                                             NaN\n",
      "account                                  70000.0\n",
      "account executive                       110000.0\n",
      "account executive insurance             120000.0\n",
      "account manager                         120000.0\n",
      "                                          ...   \n",
      "workers                                  73840.0\n",
      "young carer connector                    86361.0\n",
      "youth                                        NaN\n",
      "youth worker                             89440.0\n",
      "zone directors aboriginal identified    170300.0\n",
      "Name: max_salary, Length: 610, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# group the salaries (min and max) by title or industry and display median\n",
    "def display_salary_columns_median_grouped_by(group_by_colname):\n",
    "    print('Min Salary median per job ' + group_by_colname)\n",
    "    print(df.groupby(group_by_colname)['min_salary'].median())\n",
    "    print('-'*30)\n",
    "    print('Max Salary median per ' + group_by_colname)\n",
    "    print(df.groupby(group_by_colname)['max_salary'].median())\n",
    "    \n",
    "group_by = 'title'\n",
    "display_salary_columns_median_grouped_by(group_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aec781-cedb-43b9-8f4f-3653d40a9d19",
   "metadata": {},
   "source": [
    "We decided to use the __median because it is less prone to being affected by outliers.__\n",
    "\n",
    "Let's __proceed with the imputation using the median per industry.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0d95249d-a205-44ed-aff0-b45790fef473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_safe2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "933e2552-1915-4679-a1a3-6f9c280dd884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save medians in dictionaries\n",
    "dict_min_salary_median_per_industry = df.groupby(group_by)['min_salary'].median().to_dict()\n",
    "dict_max_salary_median_per_industry = df.groupby(group_by)['max_salary'].median().to_dict()\n",
    "\n",
    "# replace missing values in the dataframe\n",
    "def replace_missing_salaries(df, salary_colname, group_by_colname, dict_salary_median_per_industry):\n",
    "    \n",
    "    # loop through missing values and retrieve median from dictionary\n",
    "    for index, row in df[df[salary_colname].isna()].iterrows():\n",
    "        median = dict_salary_median_per_industry[row[group_by_colname]]\n",
    "        df.loc[index, salary_colname] = median\n",
    "\n",
    "# replace missing values for both min and max salaries\n",
    "replace_missing_salaries(df, 'min_salary', group_by, dict_min_salary_median_per_industry)\n",
    "replace_missing_salaries(df, 'max_salary', group_by, dict_max_salary_median_per_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b48b9b06-d69f-4c64-a8ac-d09b3befad22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Missing Values\n",
      "title           0\n",
      "company         0\n",
      "location        0\n",
      "department      0\n",
      "type            0\n",
      "industry        0\n",
      "days_ago        0\n",
      "min_salary    382\n",
      "max_salary    382\n",
      "dtype: int64\n",
      "\n",
      "% Missing Values\n",
      "title         0.000000\n",
      "company       0.000000\n",
      "location      0.000000\n",
      "department    0.000000\n",
      "type          0.000000\n",
      "industry      0.000000\n",
      "days_ago      0.000000\n",
      "min_salary    3.897959\n",
      "max_salary    3.897959\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607fd82b-4485-4c34-a6ad-48248c9108f7",
   "metadata": {},
   "source": [
    "Now that __we have very few missing values (<4% for salary columns).__\n",
    "\n",
    "This means there's no enough data to support the salaries by job 'title'.\n",
    "\n",
    "We can replace this few missing values with the job 'industry' median.\n",
    "\n",
    "Fortunately our code can be re-used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b372c960-2995-4ba6-8e91-7fe1be7007eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Salary median per job industry\n",
      "industry\n",
      "Accounting                                 80000.0\n",
      "Administration & Office Support            64063.0\n",
      "Banking & Financial Services               60000.0\n",
      "CEO & General Management                  140000.0\n",
      "Call Centre & Customer Service             68078.4\n",
      "Community Services & Development           75920.0\n",
      "Construction                               79040.0\n",
      "Education & Training                       66120.0\n",
      "Engineering                                85000.0\n",
      "Farming, Animals & Conservation            54662.4\n",
      "Government & Defence                       83200.0\n",
      "Healthcare & Medical                       66027.0\n",
      "Hospitality & Tourism                      62608.0\n",
      "Human Resources & Recruitment              90000.0\n",
      "Information & Communication Technology     70000.0\n",
      "Insurance & Superannuation                 80000.0\n",
      "Legal                                      80000.0\n",
      "Manufacturing, Transport & Logistics       64823.2\n",
      "Marketing & Communications                 71136.0\n",
      "Mining, Resources & Energy                 74000.0\n",
      "Real Estate & Property                     70000.0\n",
      "Retail & Consumer Products                 62400.0\n",
      "Sales                                      89440.0\n",
      "Science & Technology                       65000.0\n",
      "Sport & Recreation                         71136.0\n",
      "Trades & Services                          66560.0\n",
      "Name: min_salary, dtype: float64\n",
      "------------------------------\n",
      "Max Salary median per industry\n",
      "industry\n",
      "Accounting                                 90816.5\n",
      "Administration & Office Support            72800.0\n",
      "Banking & Financial Services               70000.0\n",
      "CEO & General Management                  170000.0\n",
      "Call Centre & Customer Service             72425.0\n",
      "Community Services & Development           88287.0\n",
      "Construction                               92036.0\n",
      "Education & Training                       71968.0\n",
      "Engineering                               109072.0\n",
      "Farming, Animals & Conservation            62400.0\n",
      "Government & Defence                       90775.0\n",
      "Healthcare & Medical                       73000.0\n",
      "Hospitality & Tourism                      79040.0\n",
      "Human Resources & Recruitment             106669.0\n",
      "Information & Communication Technology     85803.0\n",
      "Insurance & Superannuation                 93734.0\n",
      "Legal                                     109072.0\n",
      "Manufacturing, Transport & Logistics       72800.0\n",
      "Marketing & Communications                 85606.0\n",
      "Mining, Resources & Energy                 90000.0\n",
      "Real Estate & Property                     80000.0\n",
      "Retail & Consumer Products                 72800.0\n",
      "Sales                                     115000.0\n",
      "Science & Technology                       82348.5\n",
      "Sport & Recreation                         83200.0\n",
      "Trades & Services                          73798.0\n",
      "Name: max_salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "group_by = 'industry'\n",
    "display_salary_columns_median_grouped_by(group_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5e38d0c0-577e-4f38-b20a-b3a17b50024b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save medians in dictionaries\n",
    "dict_min_salary_median_per_industry = df.groupby(group_by)['min_salary'].median().to_dict()\n",
    "dict_max_salary_median_per_industry = df.groupby(group_by)['max_salary'].median().to_dict()\n",
    "# replace missing values for both min and max salaries\n",
    "replace_missing_salaries(df, 'min_salary', group_by, dict_min_salary_median_per_industry)\n",
    "replace_missing_salaries(df, 'max_salary', group_by, dict_max_salary_median_per_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0321047c-ebe6-4a07-a50c-4d1fc676c2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Missing Values\n",
      "title         0\n",
      "company       0\n",
      "location      0\n",
      "department    0\n",
      "type          0\n",
      "industry      0\n",
      "days_ago      0\n",
      "min_salary    0\n",
      "max_salary    0\n",
      "dtype: int64\n",
      "\n",
      "% Missing Values\n",
      "title         0.0\n",
      "company       0.0\n",
      "location      0.0\n",
      "department    0.0\n",
      "type          0.0\n",
      "industry      0.0\n",
      "days_ago      0.0\n",
      "min_salary    0.0\n",
      "max_salary    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c426b9-ca30-41e7-ad86-a6669c5bb76f",
   "metadata": {},
   "source": [
    "So, the last missing values were replaced with the median of salaries per industry.\n",
    "\n",
    "Now that we have 0 missing values, we can __proceed with duplicated rows.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ec6ed0bd-4b51-41c3-92ab-08f78ad74c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Duplicated Values\n",
      "1331\n",
      "\n",
      "% Duplicated Values\n",
      "13.581632653061224\n"
     ]
    }
   ],
   "source": [
    "check_duplicated_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d9b53-5d69-4a3a-9b5e-b19461a2669c",
   "metadata": {},
   "source": [
    "Our number of duplicated values have increased in 4% from our raw data. This may be due to the cleaning process.\n",
    "\n",
    "Let's __drop these rows as they won't add value to our analysis due to their redundancy.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "51e40a01-a28a-4f9f-bf4f-3da184320a98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_safe3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1aa1686b-1c17-47cd-8bd5-a7ab447bbe3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>type</th>\n",
       "      <th>industry</th>\n",
       "      <th>days_ago</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8464</th>\n",
       "      <td>accounts receivable officer</td>\n",
       "      <td>sydney</td>\n",
       "      <td>sydney nsw</td>\n",
       "      <td>Accounts Receivable/Credit Control</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>23</td>\n",
       "      <td>79040.0</td>\n",
       "      <td>83200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>support engineer</td>\n",
       "      <td>pty ltd</td>\n",
       "      <td>sydney nsw</td>\n",
       "      <td>Help Desk &amp; IT Support</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>23</td>\n",
       "      <td>85340.0</td>\n",
       "      <td>99700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>team leader</td>\n",
       "      <td>labourforce</td>\n",
       "      <td>park sydney nsw</td>\n",
       "      <td>Warehousing, Storage &amp; Distribution</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Manufacturing, Transport &amp; Logistics</td>\n",
       "      <td>23</td>\n",
       "      <td>97760.0</td>\n",
       "      <td>97760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>assistant</td>\n",
       "      <td>cendre</td>\n",
       "      <td>gold coast qld</td>\n",
       "      <td>Pickers &amp; Packers</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Manufacturing, Transport &amp; Logistics</td>\n",
       "      <td>23</td>\n",
       "      <td>64740.0</td>\n",
       "      <td>72800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8468</th>\n",
       "      <td>it support officer</td>\n",
       "      <td>hare forbes</td>\n",
       "      <td>sydney nsw</td>\n",
       "      <td>Help Desk &amp; IT Support</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>23</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title      company         location  \\\n",
       "8464  accounts receivable officer       sydney       sydney nsw   \n",
       "8465             support engineer      pty ltd       sydney nsw   \n",
       "8466                  team leader  labourforce  park sydney nsw   \n",
       "8467                    assistant       cendre   gold coast qld   \n",
       "8468           it support officer  hare forbes       sydney nsw   \n",
       "\n",
       "                               department           type  \\\n",
       "8464   Accounts Receivable/Credit Control  Contract/Temp   \n",
       "8465               Help Desk & IT Support      Full time   \n",
       "8466  Warehousing, Storage & Distribution  Contract/Temp   \n",
       "8467                    Pickers & Packers      Full time   \n",
       "8468               Help Desk & IT Support      Full time   \n",
       "\n",
       "                                    industry  days_ago  min_salary  max_salary  \n",
       "8464                              Accounting        23     79040.0     83200.0  \n",
       "8465  Information & Communication Technology        23     85340.0     99700.0  \n",
       "8466    Manufacturing, Transport & Logistics        23     97760.0     97760.0  \n",
       "8467    Manufacturing, Transport & Logistics        23     64740.0     72800.0  \n",
       "8468  Information & Communication Technology        23     65000.0     75000.0  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "cfc76fa2-610a-49a6-bc7e-d6d5c1013ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 8469\n",
      "Number of Columns: 9\n",
      "Index(['title', 'company', 'location', 'department', 'type', 'industry',\n",
      "       'days_ago', 'min_salary', 'max_salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "display_shape_and_colnames(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee326d41-4420-45b8-baa9-d105834e7fd9",
   "metadata": {},
   "source": [
    "After dropping duplicated rows, we are __left with 8469 rows and 9 columns.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b806f6bd-83d4-430e-b000-df65bdfcd2eb",
   "metadata": {},
   "source": [
    "### Step 3. Plotting methods for distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d90fc1",
   "metadata": {},
   "source": [
    "### Step 9. Unsupervised learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = df2.copy()\n",
    "clean_data = clean_data[['title', 'company', 'location', 'daysAgo', 'typeMapped', 'minSalary', 'maxSalary']]\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f669a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Crea un modelo de KMeans para clusterizar los datos\n",
    "##Apply encoding to the categorical columns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "for col in clean_data.select_dtypes(include=['object']).columns:\n",
    "    clean_data[col + '_encoded'] = le.fit_transform(clean_data[col])\n",
    "\n",
    "\n",
    "df_econded = clean_data[['daysAgo', 'typeMapped', 'minSalary', 'maxSalary', 'title_encoded', 'company_encoded', 'location_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfce03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_econded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bf50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check null values\n",
    "\n",
    "df_econded.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46461e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For now i will drop the null values\n",
    "df_econded = df_econded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b90948",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_econded_scaled = scaler.fit_transform(df_econded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Elbow method to find the best number of clusters\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_elbow_method(df, max_clusters):\n",
    "    wcss = []\n",
    "    for i in range(1, max_clusters):\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(df)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    plt.plot(range(1, max_clusters), wcss)\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()\n",
    "\n",
    "plot_elbow_method(df_econded_scaled, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0b690",
   "metadata": {},
   "source": [
    "Best clusterin K value is 4. We will use KMeans to cluster our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db37e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cluster k=3\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "kmeans.fit(df_econded_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new column with the cluster number\n",
    "\n",
    "df_econded['cluster'] = kmeans.labels_\n",
    "df_econded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the clusters\n",
    "\n",
    "def plot_clusters(df, x, y, hue):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df, x=x, y=y, hue=hue, palette='deep')\n",
    "    plt.title('Clusters')\n",
    "    plt.show()\n",
    "\n",
    "plot_clusters(df_econded, 'minSalary', 'maxSalary', 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bdab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f7ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbd960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1d0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
